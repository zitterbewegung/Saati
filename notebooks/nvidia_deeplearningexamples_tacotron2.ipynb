{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-aYP9T2bcBC"
   },
   "source": [
    "### This notebook requires a GPU runtime to run.\n",
    "### Please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "\n",
    "# Tacotron 2\n",
    "\n",
    "*Author: NVIDIA*\n",
    "\n",
    "**The Tacotron 2 model for generating mel spectrograms from text**\n",
    "\n",
    "<img src=\"https://pytorch.org/assets/images/tacotron2_diagram.png\" alt=\"alt\" width=\"50%\"/>\n",
    "\n",
    "\n",
    "To run the example you need some extra python packages installed.\n",
    "These are needed for preprocessing the text and audio, as well as for display and input / output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1P35LGI6bcBH"
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install numpy scipy librosa unidecode inflect librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2X8R7wuLbcBH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\r2q2/.cache\\torch\\hub\\nvidia_DeepLearningExamples_torchhub\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tacotron2 = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_tacotron2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y389IzggbcBH"
   },
   "source": [
    "will load the Tacotron2 model pre-trained on [LJ Speech dataset](https://keithito.com/LJ-Speech-Dataset/)\n",
    "\n",
    "### Model Description\n",
    "\n",
    "The Tacotron 2 and WaveGlow model form a text-to-speech system that enables user to synthesise a natural sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow (also available via torch.hub) is a flow-based model that consumes the mel spectrograms to generate speech.\n",
    "\n",
    "This implementation of Tacotron 2 model differs from the model described in the paper. Our implementation uses Dropout instead of Zoneout to regularize the LSTM layers.\n",
    "\n",
    "### Example\n",
    "\n",
    "In the example below:\n",
    "- pretrained Tacotron2 and Waveglow models are loaded from torch.hub\n",
    "- Tacotron2 generates mel spectrogram given tensor represantation of an input text (\"Hello world, I missed you\")\n",
    "- Waveglow generates sound given the mel spectrogram\n",
    "- the output sound is saved in an 'audio.wav' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pIlvAlE1bcBI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeEVjBtTbcBI"
   },
   "source": [
    "Prepare tacotron2 for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sEz6tMrPbcBI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tacotron2(\n",
       "  (embedding): Embedding(148, 512)\n",
       "  (encoder): Encoder(\n",
       "    (convolutions): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (lstm): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (prenet): Prenet(\n",
       "      (layers): ModuleList(\n",
       "        (0): LinearNorm(\n",
       "          (linear_layer): Linear(in_features=80, out_features=256, bias=False)\n",
       "        )\n",
       "        (1): LinearNorm(\n",
       "          (linear_layer): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (attention_rnn): LSTMCell(768, 1024)\n",
       "    (attention_layer): Attention(\n",
       "      (query_layer): LinearNorm(\n",
       "        (linear_layer): Linear(in_features=1024, out_features=128, bias=False)\n",
       "      )\n",
       "      (memory_layer): LinearNorm(\n",
       "        (linear_layer): Linear(in_features=512, out_features=128, bias=False)\n",
       "      )\n",
       "      (v): LinearNorm(\n",
       "        (linear_layer): Linear(in_features=128, out_features=1, bias=False)\n",
       "      )\n",
       "      (location_layer): LocationLayer(\n",
       "        (location_conv): ConvNorm(\n",
       "          (conv): Conv1d(2, 32, kernel_size=(31,), stride=(1,), padding=(15,), bias=False)\n",
       "        )\n",
       "        (location_dense): LinearNorm(\n",
       "          (linear_layer): Linear(in_features=32, out_features=128, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder_rnn): LSTMCell(1536, 1024, bias=1)\n",
       "    (linear_projection): LinearNorm(\n",
       "      (linear_layer): Linear(in_features=1536, out_features=80, bias=True)\n",
       "    )\n",
       "    (gate_layer): LinearNorm(\n",
       "      (linear_layer): Linear(in_features=1536, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (postnet): Postnet(\n",
       "    (convolutions): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 80, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tacotron2 = tacotron2.to('cuda')\n",
    "tacotron2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8717WQlybcBI"
   },
   "source": [
    "Load waveglow from PyTorch Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3hC2SfUrbcBJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\r2q2/.cache\\torch\\hub\\nvidia_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WaveGlow(\n",
       "  (upsample): ConvTranspose1d(80, 80, kernel_size=(1024,), stride=(256,))\n",
       "  (WN): ModuleList(\n",
       "    (0): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(4, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 8, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (1): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(4, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 8, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(4, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 8, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(4, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 8, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (4): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 6, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (5): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 6, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (6): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 6, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (7): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 6, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (8): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(2, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 4, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (9): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(2, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 4, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (10): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(2, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 4, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (11): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(2, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 4, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (convinv): ModuleList(\n",
       "    (0): Invertible1x1Conv(\n",
       "      (conv): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (1): Invertible1x1Conv(\n",
       "      (conv): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (2): Invertible1x1Conv(\n",
       "      (conv): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (3): Invertible1x1Conv(\n",
       "      (conv): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (4): Invertible1x1Conv(\n",
       "      (conv): Conv1d(6, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (5): Invertible1x1Conv(\n",
       "      (conv): Conv1d(6, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (6): Invertible1x1Conv(\n",
       "      (conv): Conv1d(6, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (7): Invertible1x1Conv(\n",
       "      (conv): Conv1d(6, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (8): Invertible1x1Conv(\n",
       "      (conv): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (9): Invertible1x1Conv(\n",
       "      (conv): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (10): Invertible1x1Conv(\n",
       "      (conv): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (11): Invertible1x1Conv(\n",
       "      (conv): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveglow = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_waveglow')\n",
    "waveglow = waveglow.remove_weightnorm(waveglow)\n",
    "waveglow = waveglow.to('cuda')\n",
    "waveglow.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsb-gL8pbcBJ"
   },
   "source": [
    "Now, let's make the model say *\"hello world, I missed you\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-NAUOjeebcBJ"
   },
   "outputs": [],
   "source": [
    "text = \"hello world, I missed you\"\n",
    "# preprocessing\n",
    "sequence = np.array(tacotron2.text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "sequence = torch.from_numpy(sequence).to(device='cuda', dtype=torch.int64)\n",
    "\n",
    "# run the models\n",
    "with torch.no_grad():\n",
    "    _, mel, _, _ = tacotron2.infer(sequence)\n",
    "    audio = waveglow.infer(mel)\n",
    "audio_numpy = audio[0].data.cpu().numpy()\n",
    "rate = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jgzz4TFhbcBJ"
   },
   "source": [
    "Now chain pre-processing -> tacotron2 -> waveglow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qft3YK2nbcBJ"
   },
   "outputs": [],
   "source": [
    "def taco_blenderbot(utterance: str):\n",
    "    # preprocessing\n",
    "    sequence = np.array(tacotron2.text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "    sequence = torch.from_numpy(sequence).to(device='cuda', dtype=torch.int64)\n",
    "\n",
    "    # run the models\n",
    "    with torch.no_grad():\n",
    "        _, mel, _, _ = tacotron2.infer(sequence)\n",
    "        audio = waveglow.infer(mel)\n",
    "    audio_numpy = audio[0].data.cpu().numpy()\n",
    "    rate = 22050\n",
    "    write(\"audio.wav\", rate, audio_numpy)\n",
    "    return audio_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWvrEO94bcBK"
   },
   "source": [
    "You can write it to a file and listen to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zN_8t_8-bcBK"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    TFAutoModelWithLMHead,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    BlenderbotTokenizer,\n",
    "    BlenderbotSmallTokenizer,\n",
    "    BlenderbotForConditionalGeneration,\n",
    "    Conversation,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrCq6X1vbcBK"
   },
   "source": [
    "Alternatively, play it right away in a notebook with IPython widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RoPmLbY5bcBK"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(audio_numpy, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    TFAutoModelWithLMHead,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    BlenderbotTokenizer,\n",
    "    BlenderbotSmallTokenizer,\n",
    "    BlenderbotForConditionalGeneration,\n",
    "    Conversation,\n",
    ")\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import pipeline, Conversation\n",
    "import logging, json\n",
    "from typing import List, Any, Tuple\n",
    "def blenderbot400M(utterance: str) -> List[str]:\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/blenderbot-400M-distill\")\n",
    "    inputs = tokenizer([utterance], return_tensors=\"pt\")\n",
    "    reply_ids = model.generate(**inputs)\n",
    "    responses = [\n",
    "        tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        for g in reply_ids\n",
    "    ]\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_wave_tacotron(text: str):\n",
    "    # preprocessing\n",
    "    sequence = np.array(tacotron2.text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "    sequence = torch.from_numpy(sequence).to(device='cuda', dtype=torch.int64)\n",
    "\n",
    "    # run the models\n",
    "    with torch.no_grad():\n",
    "        _, mel, _, _ = tacotron2.infer(sequence)\n",
    "        audio = waveglow.infer(mel)\n",
    "    audio_numpy = audio[0].data.cpu().numpy()\n",
    "    rate = 22050\n",
    "    write(\"audio.wav\", rate, audio_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_wave_tacotron(blenderbot400M('Whats up')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Any\n",
    "from transformers import (\n",
    "    TFAutoModelWithLMHead,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    BlenderbotTokenizer,\n",
    "    BlenderbotSmallTokenizer,\n",
    "    BlenderbotForConditionalGeneration,\n",
    "    Conversation,\n",
    ")\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tacotron2(text_to_bounce: str):\n",
    "    \"\"\"This function takes text and renders it to speech\n",
    "\n",
    "    This uses tacotron from pytorch and writes it to a file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # preprocessing\n",
    "    sequence = np.array(tacotron2.text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "    sequence = torch.from_numpy(sequence).to(device='cuda', dtype=torch.int64)\n",
    "\n",
    "    # run the models\n",
    "    with torch.no_grad():\n",
    "        _, mel, _, _ = tacotron2.infer(sequence)\n",
    "        audio = waveglow.infer(mel)\n",
    "    audio_numpy = audio[0].data.cpu().numpy()\n",
    "    rate = 22050\n",
    "    write(\"C:\\\\Users\\\\r2q2\\\\Downloads\\\\{}.wav\".format(text_to_bounce), rate, audio_numpy)\n",
    "    Audio(audio_numpy, rate=rate)\n",
    "    return (responses , audio_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvfQ9AJibcBK"
   },
   "source": [
    "### Details\n",
    "For detailed information on model input and output, training recipies, inference and performance visit: [github](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/SpeechSynthesis/Tacotron2) and/or [NGC](https://ngc.nvidia.com/catalog/model-scripts/nvidia:tacotron_2_and_waveglow_for_pytorch)\n",
    "\n",
    "### References\n",
    "\n",
    " - [Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions](https://arxiv.org/abs/1712.05884)\n",
    " - [WaveGlow: A Flow-based Generative Network for Speech Synthesis](https://arxiv.org/abs/1811.00002)\n",
    " - [Tacotron2 and WaveGlow on NGC](https://ngc.nvidia.com/catalog/model-scripts/nvidia:tacotron_2_and_waveglow_for_pytorch)\n",
    " - [Tacotron2 and Waveglow on github](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/SpeechSynthesis/Tacotron2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacotron2('hey how are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " # Copyright 2020 Adobe\n",
    " # All Rights Reserved.\n",
    " \n",
    " # NOTICE: Adobe permits you to use, modify, and distribute this file in\n",
    " # accordance with the terms of the Adobe license agreement accompanying\n",
    " # it.\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('thirdparty/AdaptiveWingLoss')\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "from src.autovc.AutoVC_mel_Convertor_retrain_version import AutoVC_mel_Convertor\n",
    "import shutil\n",
    "\n",
    "ADD_NAIVE_EYE = False\n",
    "GEN_AUDIO = True\n",
    "GEN_FLS = True\n",
    "\n",
    "DEMO_CH = 'wilk.png'\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--jpg', type=str, required=True, help='Puppet image name to animate (with filename extension), e.g. wilk.png')\n",
    "parser.add_argument('--jpg_bg', type=str, required=True, help='Puppet image background (with filename extension), e.g. wilk_bg.jpg')\n",
    "parser.add_argument('--inner_lip', default=False, action='store_true', help='add this if the puppet is created with only inner lip landmarks')\n",
    "\n",
    "parser.add_argument('--out', type=str, default='out.mp4')\n",
    "\n",
    "parser.add_argument('--load_AUTOVC_name', type=str, default='examples/ckpt/ckpt_autovc.pth')\n",
    "parser.add_argument('--load_a2l_G_name', type=str, default='examples/ckpt/ckpt_speaker_branch.pth') #ckpt_audio2landmark_g.pth') #\n",
    "parser.add_argument('--load_a2l_C_name', type=str, default='examples/ckpt/ckpt_content_branch.pth') #ckpt_audio2landmark_c.pth')\n",
    "parser.add_argument('--load_G_name', type=str, default='examples/ckpt/ckpt_116_i2i_comb.pth') #ckpt_i2i_finetune_150.pth') #ckpt_image2image.pth') #\n",
    "\n",
    "parser.add_argument('--amp_lip_x', type=float, default=2.0)\n",
    "parser.add_argument('--amp_lip_y', type=float, default=2.0)\n",
    "parser.add_argument('--amp_pos', type=float, default=0.5)\n",
    "parser.add_argument('--reuse_train_emb_list', type=str, nargs='+', default=[]) #  ['E_kmpT-EfOg']) #  ['E_kmpT-EfOg']) # ['45hn7-LXDX8'])\n",
    "\n",
    "\n",
    "parser.add_argument('--add_audio_in', default=False, action='store_true')\n",
    "parser.add_argument('--comb_fan_awing', default=False, action='store_true')\n",
    "parser.add_argument('--output_folder', type=str, default='examples_cartoon')\n",
    "\n",
    "#### NEW POSE MODEL\n",
    "parser.add_argument('--test_end2end', default=True, action='store_true')\n",
    "parser.add_argument('--dump_dir', type=str, default='', help='')\n",
    "parser.add_argument('--pos_dim', default=7, type=int)\n",
    "parser.add_argument('--use_prior_net', default=True, action='store_true')\n",
    "parser.add_argument('--transformer_d_model', default=32, type=int)\n",
    "parser.add_argument('--transformer_N', default=2, type=int)\n",
    "parser.add_argument('--transformer_heads', default=2, type=int)\n",
    "parser.add_argument('--spk_emb_enc_size', default=16, type=int)\n",
    "parser.add_argument('--init_content_encoder', type=str, default='')\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help='learning rate')\n",
    "parser.add_argument('--reg_lr', type=float, default=1e-6, help='weight decay')\n",
    "parser.add_argument('--write', default=False, action='store_true')\n",
    "parser.add_argument('--segment_batch_size', type=int, default=512, help='batch size')\n",
    "parser.add_argument('--emb_coef', default=3.0, type=float)\n",
    "parser.add_argument('--lambda_laplacian_smooth_loss', default=1.0, type=float)\n",
    "parser.add_argument('--use_11spk_only', default=False, action='store_true')\n",
    "\n",
    "\n",
    "opt_parser = parser.parse_args()\n",
    "\n",
    "DEMO_CH = opt_parser.jpg.split('.')[0]\n",
    "\n",
    "shape_3d = np.loadtxt('examples_cartoon/{}_face_close_mouth.txt'.format(DEMO_CH))\n",
    "\n",
    "''' STEP 3: Generate audio data as input to audio branch '''\n",
    "au_data = []\n",
    "au_emb = []\n",
    "ains = glob.glob1('examples', '*.wav')\n",
    "ains = [item for item in ains if item is not 'tmp.wav']\n",
    "ains.sort()\n",
    "for ain in ains:\n",
    "    os.system('ffmpeg -y -loglevel error -i examples/{} -ar 16000 examples/tmp.wav'.format(ain))\n",
    "    shutil.copyfile('examples/tmp.wav', 'examples/{}'.format(ain))\n",
    "\n",
    "    # au embedding\n",
    "    from thirdparty.resemblyer_util.speaker_emb import get_spk_emb\n",
    "    me, ae = get_spk_emb('examples/{}'.format(ain))\n",
    "    au_emb.append(me.reshape(-1))\n",
    "\n",
    "    print('Processing audio file', ain)\n",
    "    c = AutoVC_mel_Convertor('examples')\n",
    "    au_data_i = c.convert_single_wav_to_autovc_input(audio_filename=os.path.join('examples', ain),\n",
    "           autovc_model_path=opt_parser.load_AUTOVC_name)\n",
    "    au_data += au_data_i\n",
    "    # os.remove(os.path.join('examples', 'tmp.wav'))\n",
    "if(os.path.isfile('examples/tmp.wav')):\n",
    "    os.remove('examples/tmp.wav')\n",
    "\n",
    "fl_data = []\n",
    "rot_tran, rot_quat, anchor_t_shape = [], [], []\n",
    "for au, info in au_data:\n",
    "    au_length = au.shape[0]\n",
    "    fl = np.zeros(shape=(au_length, 68 * 3))\n",
    "    fl_data.append((fl, info))\n",
    "    rot_tran.append(np.zeros(shape=(au_length, 3, 4)))\n",
    "    rot_quat.append(np.zeros(shape=(au_length, 4)))\n",
    "    anchor_t_shape.append(np.zeros(shape=(au_length, 68 * 3)))\n",
    "\n",
    "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_fl.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_fl.pickle'))\n",
    "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_fl_interp.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_fl_interp.pickle'))\n",
    "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_au.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_au.pickle'))\n",
    "if (os.path.exists(os.path.join('examples', 'dump', 'random_val_gaze.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_gaze.pickle'))\n",
    "\n",
    "with open(os.path.join('examples', 'dump', 'random_val_fl.pickle'), 'wb') as fp:\n",
    "    pickle.dump(fl_data, fp)\n",
    "with open(os.path.join('examples', 'dump', 'random_val_au.pickle'), 'wb') as fp:\n",
    "    pickle.dump(au_data, fp)\n",
    "with open(os.path.join('examples', 'dump', 'random_val_gaze.pickle'), 'wb') as fp:\n",
    "    gaze = {'rot_trans':rot_tran, 'rot_quat':rot_quat, 'anchor_t_shape':anchor_t_shape}\n",
    "    pickle.dump(gaze, fp)\n",
    "\n",
    "\n",
    "''' STEP 4: RUN audio->landmark network'''\n",
    "from src.approaches.train_audio2landmark import Audio2landmark_model\n",
    "model = Audio2landmark_model(opt_parser, jpg_shape=shape_3d)\n",
    "if(len(opt_parser.reuse_train_emb_list) == 0):\n",
    "    model.test(au_emb=au_emb)\n",
    "else:\n",
    "    model.test(au_emb=None)\n",
    "print('finish gen fls')\n",
    "\n",
    "''' STEP 5: de-normalize the output to the original image scale '''\n",
    "fls_names = glob.glob1('examples_cartoon', 'pred_fls_*.txt')\n",
    "fls_names.sort()\n",
    "\n",
    "for i in range(0,len(fls_names)):\n",
    "    ains = glob.glob1('examples', '*.wav')\n",
    "    ains.sort()\n",
    "    ain = ains[i]\n",
    "    fl = np.loadtxt(os.path.join('examples_cartoon', fls_names[i])).reshape((-1, 68,3))\n",
    "    output_dir = os.path.join('examples_cartoon', fls_names[i][:-4])\n",
    "    try:\n",
    "        os.makedirs(output_dir)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    from util.utils import get_puppet_info\n",
    "\n",
    "    bound, scale, shift = get_puppet_info(DEMO_CH, ROOT_DIR='examples_cartoon')\n",
    "\n",
    "    fls = fl.reshape((-1, 68, 3))\n",
    "\n",
    "    fls[:, :, 0:2] = -fls[:, :, 0:2]\n",
    "    fls[:, :, 0:2] = (fls[:, :, 0:2] / scale)\n",
    "    fls[:, :, 0:2] -= shift.reshape(1, 2)\n",
    "\n",
    "    fls = fls.reshape(-1, 204)\n",
    "\n",
    "    # additional smooth\n",
    "    from scipy.signal import savgol_filter\n",
    "    fls[:, 0:48*3] = savgol_filter(fls[:, 0:48*3], 17, 3, axis=0)\n",
    "    fls[:, 48*3:] = savgol_filter(fls[:, 48*3:], 11, 3, axis=0)\n",
    "    fls = fls.reshape((-1, 68, 3))\n",
    "\n",
    "    # if (DEMO_CH in ['paint', 'mulaney', 'cartoonM', 'beer', 'color', 'JohnMulaney', 'vangogh', 'jm', 'roy', 'lineface']):\n",
    "    if(not opt_parser.inner_lip):\n",
    "        r = list(range(0, 68))\n",
    "        fls = fls[:, r, :]\n",
    "        fls = fls[:, :, 0:2].reshape(-1, 68 * 2)\n",
    "        fls = np.concatenate((fls, np.tile(bound, (fls.shape[0], 1))), axis=1)\n",
    "        fls = fls.reshape(-1, 160)\n",
    "\n",
    "    else:\n",
    "        r = list(range(0, 48)) + list(range(60, 68))\n",
    "        fls = fls[:, r, :]\n",
    "        fls = fls[:, :, 0:2].reshape(-1, 56 * 2)\n",
    "        fls = np.concatenate((fls, np.tile(bound, (fls.shape[0], 1))), axis=1)\n",
    "        fls = fls.reshape(-1, 112 + bound.shape[1])\n",
    "\n",
    "    np.savetxt(os.path.join(output_dir, 'warped_points.txt'), fls, fmt='%.2f')\n",
    "\n",
    "    # static_points.txt\n",
    "    static_frame = np.loadtxt(os.path.join('examples_cartoon', '{}_face_open_mouth.txt'.format(DEMO_CH)))\n",
    "    static_frame = static_frame[r, 0:2]\n",
    "    static_frame = np.concatenate((static_frame, bound.reshape(-1, 2)), axis=0)\n",
    "    np.savetxt(os.path.join(output_dir, 'reference_points.txt'), static_frame, fmt='%.2f')\n",
    "\n",
    "    # triangle_vtx_index.txt\n",
    "    shutil.copy(os.path.join('examples_cartoon', DEMO_CH + '_delauney_tri.txt'),\n",
    "                os.path.join(output_dir, 'triangulation.txt'))\n",
    "\n",
    "    os.remove(os.path.join('examples_cartoon', fls_names[i]))\n",
    "\n",
    "    # ==============================================\n",
    "    # Step 4 : Vector art morphing\n",
    "    # ==============================================\n",
    "    warp_exe = os.path.join(os.getcwd(), 'facewarp', 'facewarp.exe')\n",
    "    import os\n",
    "    \n",
    "    if (os.path.exists(os.path.join(output_dir, 'output'))):\n",
    "        shutil.rmtree(os.path.join(output_dir, 'output'))\n",
    "    os.mkdir(os.path.join(output_dir, 'output'))\n",
    "    os.chdir('{}'.format(os.path.join(output_dir, 'output')))\n",
    "    cur_dir = os.getcwd()\n",
    "    print(cur_dir)\n",
    "    \n",
    "    if(os.name == 'nt'): \n",
    "        ''' windows '''\n",
    "        os.system('{} {} {} {} {} {}'.format(\n",
    "            warp_exe,\n",
    "            os.path.join(cur_dir, '..', '..', opt_parser.jpg),\n",
    "            os.path.join(cur_dir, '..', 'triangulation.txt'),\n",
    "            os.path.join(cur_dir, '..', 'reference_points.txt'),\n",
    "            os.path.join(cur_dir, '..', 'warped_points.txt'),\n",
    "            os.path.join(cur_dir, '..', '..', opt_parser.jpg_bg),\n",
    "            '-novsync -dump'))\n",
    "    else:\n",
    "        ''' linux '''\n",
    "        os.system('wine {} {} {} {} {} {}'.format(\n",
    "            warp_exe,\n",
    "            os.path.join(cur_dir, '..', '..', opt_parser.jpg),\n",
    "            os.path.join(cur_dir, '..', 'triangulation.txt'),\n",
    "            os.path.join(cur_dir, '..', 'reference_points.txt'),\n",
    "            os.path.join(cur_dir, '..', 'warped_points.txt'),\n",
    "            os.path.join(cur_dir, '..', '..', opt_parser.jpg_bg),\n",
    "            '-novsync -dump'))\n",
    "    os.system('ffmpeg -y -r 62.5 -f image2 -i \"%06d.tga\" -i {} -pix_fmt yuv420p -vf \"pad=ceil(iw/2)*2:ceil(ih/2)*2\" -shortest -strict -2 {}'.format(\n",
    "        os.path.join(cur_dir, '..', '..', '..', 'examples', ain),\n",
    "        os.path.join(cur_dir, '..', 'out.mp4')\n",
    "    ))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "nvidia_deeplearningexamples_tacotron2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
