{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc363513",
   "metadata": {
    "id": "dwFXS0vUzsfO"
   },
   "source": [
    "# MakeItTalk + text to speech and speech recognition\n",
    "\n",
    "- included project setup + pretrained model download\n",
    "- provides step-by-step details\n",
    "- todo: tdlr version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ef7dc",
   "metadata": {
    "id": "NVAYGCMEwDwB"
   },
   "source": [
    "Start make it talk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb054fd",
   "metadata": {
    "id": "QVedbX194R-A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git clone project and install requirements...\n",
      "[WinError 2] The system cannot find the file specified: 'MakeItTalk/'\n",
      "C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "'export' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "The syntax of the command is incorrect.\n",
      "The syntax of the command is incorrect.\n",
      "The syntax of the command is incorrect.\n",
      "The syntax of the command is incorrect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Download pre-trained models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "'gdown' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'gdown' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'gdown' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'gdown' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'gdown' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'ln' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr  4 11:19:41 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 461.92       Driver Version: 461.92       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX          WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 41%   45C    P8    14W / 280W |    841MiB / 24576MiB |      6%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla M40 24GB      TCC  | 00000000:23:00.0 Off |                    0 |\n",
      "| N/A   48C    P8    17W / 250W |      9MiB / 22975MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1924    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      1944    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A      2068    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A      9396    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     10424    C+G   ...p-2.7.1\\GitHubDesktop.exe    N/A      |\n",
      "|    0   N/A  N/A     10468    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11064    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11440    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     12228    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12280    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     12908    C+G   ...f.win7\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     14816    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     14972    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     20016    C+G   ...b3d8bbwe\\WinStore.App.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Git clone project and install requirements...')\n",
    "!git clone https://github.com/yzhou359/MakeItTalk #&> /dev/null\n",
    "%cd MakeItTalk/\n",
    "#!export PYTHONPATH=/content/MakeItTalk:$PYTHONPATH\n",
    "!pip install -r requirements.txt &> /dev/null\n",
    "!pip install tensorboardX &> /dev/null\n",
    "!mkdir examples/dump\n",
    "!mkdir examples/ckpt\n",
    "!pip install gdown &> /dev/null\n",
    "print('Done!')\n",
    "print('Download pre-trained models...') \n",
    "!gdown -O examples/ckpt/ckpt_autovc.pth https://drive.google.com/uc?id=1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x\n",
    "!gdown -O examples/ckpt/ckpt_content_branch.pth https://drive.google.com/uc?id=1r3bfEvTVl6pCNw5xwUhEglwDHjWtAqQp\n",
    "!gdown -O examples/ckpt/ckpt_speaker_branch.pth https://drive.google.com/uc?id=1rV0jkyDqPW-aDJcj7xSO6Zt1zSXqn1mu\n",
    "!gdown -O examples/ckpt/ckpt_116_i2i_comb.pth https://drive.google.com/uc?id=1i2LJXKp-yWKIEEgJ7C6cE3_2NirfY_0a\n",
    "!gdown -O examples/dump/emb.pickle https://drive.google.com/uc?id=18-0CYl5E6ungS3H4rRSHjfYvvm-WwjTI\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "import subprocess\n",
    "print(subprocess.getoutput('nvidia-smi'))\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad09313",
   "metadata": {
    "id": "aW4ktjHB89Du"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/huggingface/datasets.git\n",
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "!pip install torchaudio\n",
    "!pip install librosa\n",
    "!pip install jiwer\n",
    "!pip install ffmpeg-python\n",
    "!conda install -c conda-forge ipywidgets\n",
    "!pip install speech_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8075b58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Using cached SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.8.1\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# obtain path to \"english.wav\" in the same folder as this script\n",
    "from os import path\n",
    "AUDIO_FILE = path.join(path.dirname(path.realpath(__file__)), \"english.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee576f4",
   "metadata": {
    "id": "YvnAhX7RTky-"
   },
   "source": [
    "Here we are performing speech recognition to get the utterance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c583133",
   "metadata": {
    "id": "vaSJEWDf4R03"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e940e447fc44c90ab0f3fb0a86bcf87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=843.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33568773d41641d4a1ff44300f08f02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=377667514.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99d6a0166f8432b83f3eec72b327e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5019.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and preparing dataset librispeech_asr/clean (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to C:\\Users\\r2q2\\.cache\\huggingface\\datasets\\librispeech_asr\\clean\\2.1.0\\468ec03677f46a8714ac6b5b64dba02d246a228d92cbbad7f3dc190fa039eab1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8dd259ec0014a6bb0f5bae0b538824c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=9078094.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset librispeech_asr downloaded and prepared to C:\\Users\\r2q2\\.cache\\huggingface\\datasets\\librispeech_asr\\clean\\2.1.0\\468ec03677f46a8714ac6b5b64dba02d246a228d92cbbad7f3dc190fa039eab1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf482fb4afd4d29ae5adeb808f66f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=73.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function.Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(53.4790, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "input_values = processor(ds[\"speech\"][0], return_tensors=\"pt\").input_values  # Batch size 1\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "\n",
    "# compute loss\n",
    "target_transcription = \"A MAN SAID TO THE UNIVERSE SIR I EXIST\"\n",
    "\n",
    "# wrap processor as target processor to encode labels\n",
    "with processor.as_target_processor():\n",
    "    labels = processor(transcription, return_tensors=\"pt\").input_ids\n",
    "\n",
    "loss = model(input_values, labels=labels).loss\n",
    "transcription\n",
    "loss #TODO this needs to be looked in to or not used for this tech demo because it really isn't required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5bd906b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
      "Reusing dataset librispeech_asr (C:\\Users\\r2q2\\.cache\\huggingface\\datasets\\librispeech_asr\\clean\\2.1.0\\468ec03677f46a8714ac6b5b64dba02d246a228d92cbbad7f3dc190fa039eab1)\n",
      "Loading cached processed dataset at C:\\Users\\r2q2\\.cache\\huggingface\\datasets\\librispeech_asr\\clean\\2.1.0\\468ec03677f46a8714ac6b5b64dba02d246a228d92cbbad7f3dc190fa039eab1\\cache-27f4be30f66ae10e.arrow\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function.Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"patrickvonplaten/wav2vec2-base-timit-demo\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"patrickvonplaten/wav2vec2-base-timit-demo\")\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "ds = ds.map(map_to_array)\n",
    "input_values = processor(ds[\"speech\"][0], return_tensors=\"pt\").input_values  # Batch size 1\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "# compute loss\n",
    "target_transcription = \"A MAN SAID TO THE UNIVERSE SIR I EXIST\"\n",
    "# wrap processor as target processor to encode labels\n",
    "with processor.as_target_processor():\n",
    "    labels = processor(transcription, return_tensors=\"pt\").input_ids\n",
    "loss = model(input_values, labels=labels).loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14217dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"mister quiltar is the ippossiale of the midle classis and we'are glad to welcome his gosbale\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf549ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9850233f67a4004af28f280c245dd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=160.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12dc341da03b481a923d6a8b20adfbce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=69594.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cb2527fbb14b679d05d3b991c91a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=346351599.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted class: Egyptian cat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7df18a",
   "metadata": {
    "id": "p6epEN6BbGn2"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from jiwer import wer\n",
    "\n",
    "\n",
    "librispeech_eval = load_dataset(\"librispeech_asr\", \"clean\", split=\"test\")\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\").to(\"cuda\")\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "librispeech_eval = librispeech_eval.map(map_to_array)\n",
    "\n",
    "def map_to_pred(batch):\n",
    "    input_values = tokenizer(batch[\"speech\"], return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values.to(\"cuda\")).logits\n",
    "\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = tokenizer.batch_decode(predicted_ids)\n",
    "    batch[\"transcription\"] = transcription\n",
    "    return batch\n",
    "\n",
    "result = librispeech_eval.map(map_to_pred, batched=True, batch_size=1, remove_columns=[\"speech\"])\n",
    "\n",
    "print(\"WER:\", wer(result[\"text\"], result[\"transcription\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea73bd",
   "metadata": {
    "id": "lbNQC_L2TwNW"
   },
   "source": [
    "Based on the recognised transcription we pass this into blenderbot-400-distill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1059568",
   "metadata": {
    "id": "eNi7NnsTYWIC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3884c",
   "metadata": {
    "id": "Zb-UjOzD-zjT"
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import (\n",
    "    TFAutoModelWithLMHead,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    BlenderbotTokenizer,\n",
    "    BlenderbotSmallTokenizer,\n",
    "    BlenderbotForConditionalGeneration,\n",
    "    Conversation,\n",
    ")\n",
    "#from transformers import RobertaTokenizer, IBertModel\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import pipeline, Conversation\n",
    "#import logging\n",
    "from typing import List\n",
    "\n",
    "#conversational_pipeline = pipeline(\"conversational\", device=0)\n",
    "\n",
    "def blenderbot400M(utterance: str) -> List[str]:\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/blenderbot-400M-distill\").to('cuda')\n",
    "    inputs = tokenizer([utterance], return_tensors=\"pt\")\n",
    "    reply_ids = model.generate(**inputs)\n",
    "    responses = [\n",
    "        tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        for g in reply_ids\n",
    "    ]\n",
    "    return responses\n",
    "\n",
    "blenderbot400M(transcription[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231fe99",
   "metadata": {
    "id": "lJ0yNirUU6dV"
   },
   "outputs": [],
   "source": [
    "blenderbot400M(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6247a9",
   "metadata": {
    "id": "93HLLOhSV5B8"
   },
   "source": [
    "Here we download mozillas TTS and use one of their models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7fe82dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Using cached gdown-3.12.2.tar.gz (8.2 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from gdown) (3.0.12)\n",
      "Requirement already satisfied: tqdm in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from gdown) (4.49.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from gdown) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from requests[socks]->gdown) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from requests[socks]->gdown) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from requests[socks]->gdown) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from requests[socks]->gdown) (4.0.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (PEP 517): started\n",
      "  Building wheel for gdown (PEP 517): finished with status 'done'\n",
      "  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9681 sha256=b5e057b2c2d68c2e00826b4d11d87f64712d43d2c82cddc8d7583aded5165327\n",
      "  Stored in directory: c:\\users\\r2q2\\appdata\\local\\pip\\cache\\wheels\\e2\\62\\1e\\926d1ebe7b1e733c78d627fd288d01b83feaf67efc06e0e4c3\n",
      "Successfully built gdown\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-3.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46f06e53",
   "metadata": {
    "id": "xLFK2Re2cXeu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1dntzjWFg7ufWaTaFy80nRz-Tu02xWZos\n",
      "To: C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\tts_model.pth.tar\n",
      "\n",
      "0.00B [00:00, ?B/s]\n",
      "524kB [00:00, 3.81MB/s]\n",
      "1.57MB [00:00, 4.49MB/s]\n",
      "2.62MB [00:00, 5.19MB/s]\n",
      "4.19MB [00:00, 6.47MB/s]\n",
      "5.77MB [00:00, 7.14MB/s]\n",
      "7.34MB [00:00, 8.37MB/s]\n",
      "8.39MB [00:00, 8.37MB/s]\n",
      "9.96MB [00:01, 9.54MB/s]\n",
      "11.5MB [00:01, 9.91MB/s]\n",
      "13.1MB [00:01, 10.2MB/s]\n",
      "14.7MB [00:01, 9.18MB/s]\n",
      "16.8MB [00:01, 10.6MB/s]\n",
      "18.4MB [00:01, 10.1MB/s]\n",
      "19.9MB [00:01, 11.3MB/s]\n",
      "21.5MB [00:02, 10.4MB/s]\n",
      "23.1MB [00:02, 11.5MB/s]\n",
      "24.6MB [00:02, 11.5MB/s]\n",
      "26.2MB [00:02, 11.4MB/s]\n",
      "27.8MB [00:02, 10.4MB/s]\n",
      "29.4MB [00:02, 11.3MB/s]\n",
      "30.9MB [00:02, 11.0MB/s]\n",
      "32.5MB [00:03, 10.9MB/s]\n",
      "34.1MB [00:03, 10.5MB/s]\n",
      "35.7MB [00:03, 10.4MB/s]\n",
      "37.4MB [00:03, 11.1MB/s]\n",
      "38.9MB [00:03, 10.9MB/s]\n",
      "40.5MB [00:03, 10.7MB/s]\n",
      "41.8MB [00:03, 10.3MB/s]\n",
      "43.4MB [00:04, 11.2MB/s]\n",
      "45.0MB [00:04, 10.9MB/s]\n",
      "46.1MB [00:04, 9.86MB/s]\n",
      "47.7MB [00:04, 10.2MB/s]\n",
      "49.3MB [00:04, 10.9MB/s]\n",
      "50.9MB [00:04, 10.7MB/s]\n",
      "52.4MB [00:04, 10.1MB/s]\n",
      "54.0MB [00:05, 11.1MB/s]\n",
      "55.4MB [00:05, 11.1MB/s]\n",
      "57.0MB [00:05, 11.1MB/s]\n",
      "58.5MB [00:05, 10.4MB/s]\n",
      "60.1MB [00:05, 11.0MB/s]\n",
      "61.7MB [00:05, 11.1MB/s]\n",
      "63.3MB [00:05, 10.8MB/s]\n",
      "64.9MB [00:06, 10.3MB/s]\n",
      "66.4MB [00:06, 9.98MB/s]\n",
      "68.5MB [00:06, 10.5MB/s]\n",
      "70.4MB [00:06, 9.85MB/s]\n",
      "72.4MB [00:06, 11.3MB/s]\n",
      "74.0MB [00:06, 10.9MB/s]\n",
      "75.6MB [00:07, 10.6MB/s]\n",
      "76.9MB [00:07, 10.9MB/s]\n",
      "78.4MB [00:07, 10.4MB/s]\n",
      "80.3MB [00:07, 11.3MB/s]\n",
      "81.8MB [00:07, 11.5MB/s]\n",
      "83.4MB [00:07, 10.3MB/s]\n",
      "85.0MB [00:07, 10.1MB/s]\n",
      "86.5MB [00:08, 8.85MB/s]\n",
      "87.5MB [00:08, 8.44MB/s]\n",
      "89.2MB [00:08, 9.75MB/s]\n",
      "90.8MB [00:08, 10.1MB/s]\n",
      "92.3MB [00:08, 10.3MB/s]\n",
      "93.5MB [00:08, 9.45MB/s]\n",
      "95.0MB [00:08, 10.6MB/s]\n",
      "96.6MB [00:09, 10.8MB/s]\n",
      "97.8MB [00:09, 9.74MB/s]\n",
      "99.3MB [00:09, 10.2MB/s]\n",
      "101MB [00:09, 11.2MB/s] \n",
      "102MB [00:09, 10.8MB/s]\n",
      "104MB [00:09, 10.6MB/s]\n",
      "105MB [00:09, 10.9MB/s]\n",
      "107MB [00:10, 11.1MB/s]\n",
      "109MB [00:10, 11.1MB/s]\n",
      "110MB [00:10, 10.5MB/s]\n",
      "112MB [00:10, 11.3MB/s]\n",
      "113MB [00:10, 10.6MB/s]\n",
      "115MB [00:10, 10.8MB/s]\n",
      "116MB [00:10, 10.6MB/s]\n",
      "118MB [00:11, 10.4MB/s]\n",
      "120MB [00:11, 11.3MB/s]\n",
      "122MB [00:11, 11.3MB/s]\n",
      "123MB [00:11, 11.0MB/s]\n",
      "125MB [00:11, 10.7MB/s]\n",
      "126MB [00:11, 10.3MB/s]\n",
      "128MB [00:12, 9.99MB/s]\n",
      "130MB [00:12, 11.3MB/s]\n",
      "132MB [00:12, 11.4MB/s]\n",
      "133MB [00:12, 10.9MB/s]\n",
      "135MB [00:12, 10.4MB/s]\n",
      "136MB [00:12, 10.6MB/s]\n",
      "139MB [00:13, 10.7MB/s]\n",
      "140MB [00:13, 11.7MB/s]\n",
      "142MB [00:13, 11.5MB/s]\n",
      "143MB [00:13, 10.6MB/s]\n",
      "145MB [00:13, 10.5MB/s]\n",
      "146MB [00:13, 11.4MB/s]\n",
      "148MB [00:13, 10.9MB/s]\n",
      "150MB [00:13, 10.9MB/s]\n",
      "151MB [00:14, 10.2MB/s]\n",
      "153MB [00:14, 10.3MB/s]\n",
      "155MB [00:14, 10.9MB/s]\n",
      "157MB [00:14, 11.3MB/s]\n",
      "158MB [00:14, 11.3MB/s]\n",
      "160MB [00:14, 10.8MB/s]\n",
      "161MB [00:15, 10.5MB/s]\n",
      "163MB [00:15, 11.4MB/s]\n",
      "164MB [00:15, 11.1MB/s]\n",
      "166MB [00:15, 10.6MB/s]\n",
      "167MB [00:15, 10.1MB/s]\n",
      "168MB [00:15, 9.49MB/s]\n",
      "169MB [00:15, 8.51MB/s]\n",
      "170MB [00:16, 9.02MB/s]\n",
      "172MB [00:16, 9.02MB/s]\n",
      "173MB [00:16, 8.84MB/s]\n",
      "176MB [00:16, 9.60MB/s]\n",
      "178MB [00:16, 9.79MB/s]\n",
      "179MB [00:16, 10.7MB/s]\n",
      "181MB [00:17, 11.2MB/s]\n",
      "182MB [00:17, 10.6MB/s]\n",
      "184MB [00:17, 10.1MB/s]\n",
      "185MB [00:17, 11.0MB/s]\n",
      "187MB [00:17, 11.1MB/s]\n",
      "189MB [00:17, 11.1MB/s]\n",
      "190MB [00:17, 10.2MB/s]\n",
      "192MB [00:18, 10.1MB/s]\n",
      "194MB [00:18, 11.0MB/s]\n",
      "195MB [00:18, 11.1MB/s]\n",
      "197MB [00:18, 10.6MB/s]\n",
      "198MB [00:18, 10.4MB/s]\n",
      "200MB [00:18, 10.2MB/s]\n",
      "201MB [00:18, 11.2MB/s]\n",
      "203MB [00:19, 10.8MB/s]\n",
      "204MB [00:19, 10.4MB/s]\n",
      "206MB [00:19, 10.5MB/s]\n",
      "208MB [00:19, 11.4MB/s]\n",
      "209MB [00:19, 11.3MB/s]\n",
      "211MB [00:19, 11.0MB/s]\n",
      "212MB [00:19, 10.4MB/s]\n",
      "214MB [00:20, 10.4MB/s]\n",
      "216MB [00:20, 10.5MB/s]\n",
      "218MB [00:20, 11.5MB/s]\n",
      "219MB [00:20, 11.1MB/s]\n",
      "221MB [00:20, 10.9MB/s]\n",
      "222MB [00:20, 10.6MB/s]\n",
      "224MB [00:21, 10.6MB/s]\n",
      "226MB [00:21, 11.5MB/s]\n",
      "227MB [00:21, 11.0MB/s]\n",
      "229MB [00:21, 10.7MB/s]\n",
      "230MB [00:21, 9.81MB/s]\n",
      "232MB [00:21, 10.7MB/s]\n",
      "233MB [00:21, 10.8MB/s]\n",
      "234MB [00:21, 10.1MB/s]\n",
      "236MB [00:22, 9.70MB/s]\n",
      "237MB [00:22, 9.08MB/s]\n",
      "239MB [00:22, 8.44MB/s]\n",
      "240MB [00:22, 9.67MB/s]\n",
      "242MB [00:22, 10.4MB/s]\n",
      "243MB [00:22, 10.3MB/s]\n",
      "245MB [00:23, 10.2MB/s]\n",
      "246MB [00:23, 10.8MB/s]\n",
      "248MB [00:23, 10.6MB/s]\n",
      "249MB [00:23, 10.8MB/s]\n",
      "251MB [00:23, 10.3MB/s]\n",
      "252MB [00:23, 10.3MB/s]\n",
      "254MB [00:23, 10.6MB/s]\n",
      "256MB [00:24, 11.5MB/s]\n",
      "257MB [00:24, 11.5MB/s]\n",
      "259MB [00:24, 10.8MB/s]\n",
      "260MB [00:24, 11.4MB/s]\n",
      "262MB [00:24, 10.8MB/s]\n",
      "263MB [00:24, 10.4MB/s]\n",
      "265MB [00:24, 11.4MB/s]\n",
      "266MB [00:24, 11.0MB/s]\n",
      "268MB [00:25, 10.7MB/s]\n",
      "269MB [00:25, 10.3MB/s]\n",
      "271MB [00:25, 10.0MB/s]\n",
      "273MB [00:25, 10.8MB/s]\n",
      "275MB [00:25, 10.8MB/s]\n",
      "277MB [00:25, 11.7MB/s]\n",
      "279MB [00:26, 11.2MB/s]\n",
      "280MB [00:26, 11.2MB/s]\n",
      "281MB [00:26, 11.1MB/s]\n",
      "283MB [00:26, 11.1MB/s]\n",
      "284MB [00:26, 11.2MB/s]\n",
      "286MB [00:26, 10.1MB/s]\n",
      "288MB [00:26, 11.2MB/s]\n",
      "289MB [00:27, 11.6MB/s]\n",
      "291MB [00:27, 11.5MB/s]\n",
      "292MB [00:27, 10.7MB/s]\n",
      "294MB [00:27, 8.86MB/s]\n",
      "296MB [00:27, 9.70MB/s]\n",
      "297MB [00:27, 9.63MB/s]\n",
      "298MB [00:28, 9.22MB/s]\n",
      "299MB [00:28, 10.4MB/s]\n",
      "301MB [00:28, 9.93MB/s]\n",
      "302MB [00:28, 10.6MB/s]\n",
      "304MB [00:28, 10.5MB/s]\n",
      "305MB [00:28, 10.7MB/s]\n",
      "307MB [00:28, 10.2MB/s]\n",
      "309MB [00:29, 10.2MB/s]\n",
      "310MB [00:29, 9.90MB/s]\n",
      "312MB [00:29, 11.4MB/s]\n",
      "314MB [00:29, 11.1MB/s]\n",
      "315MB [00:29, 10.9MB/s]\n",
      "317MB [00:29, 10.2MB/s]\n",
      "319MB [00:29, 9.58MB/s]\n",
      "321MB [00:30, 11.2MB/s]\n",
      "322MB [00:30, 10.9MB/s]\n",
      "324MB [00:30, 10.6MB/s]\n",
      "325MB [00:30, 9.08MB/s]\n",
      "327MB [00:30, 10.6MB/s]\n",
      "329MB [00:30, 10.3MB/s]\n",
      "330MB [00:30, 11.2MB/s]\n",
      "332MB [00:31, 10.8MB/s]\n",
      "333MB [00:31, 10.5MB/s]\n",
      "335MB [00:31, 11.4MB/s]\n",
      "336MB [00:31, 11.3MB/s]\n",
      "338MB [00:31, 11.1MB/s]\n",
      "340MB [00:31, 10.2MB/s]\n",
      "341MB [00:31, 11.4MB/s]\n",
      "343MB [00:32, 11.0MB/s]\n",
      "344MB [00:32, 10.8MB/s]\n",
      "346MB [00:32, 10.4MB/s]\n",
      "347MB [00:32, 10.7MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=18CQ6G6tBEOfvCHlPqP8EBI4xWbrr9dBc\n",
      "To: C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\config.json\n",
      "\n",
      "  0%|          | 0.00/9.53k [00:00<?, ?B/s]\n",
      "100%|##########| 9.53k/9.53k [00:00<?, ?B/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Ty5DZdOc0F7OTGj9oJThYbL5iVu_2G0K\n",
      "To: C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\vocoder_model.pth.tar\n",
      "\n",
      "0.00B [00:00, ?B/s]\n",
      "1.05MB [00:00, 6.85MB/s]\n",
      "2.10MB [00:00, 7.49MB/s]\n",
      "3.67MB [00:00, 8.52MB/s]\n",
      "4.72MB [00:00, 8.82MB/s]\n",
      "6.29MB [00:00, 10.0MB/s]\n",
      "7.86MB [00:00, 10.4MB/s]\n",
      "8.91MB [00:00, 10.1MB/s]\n",
      "10.5MB [00:00, 10.7MB/s]\n",
      "12.1MB [00:01, 10.9MB/s]\n",
      "13.6MB [00:01, 11.4MB/s]\n",
      "15.2MB [00:01, 11.3MB/s]\n",
      "16.8MB [00:01, 10.7MB/s]\n",
      "18.4MB [00:01, 11.4MB/s]\n",
      "19.9MB [00:01, 11.1MB/s]\n",
      "21.5MB [00:01, 11.2MB/s]\n",
      "23.1MB [00:02, 11.9MB/s]\n",
      "24.6MB [00:02, 11.5MB/s]\n",
      "26.2MB [00:02, 11.4MB/s]\n",
      "27.8MB [00:02, 11.7MB/s]\n",
      "29.4MB [00:02, 11.6MB/s]\n",
      "30.9MB [00:02, 11.8MB/s]\n",
      "32.5MB [00:02, 11.7MB/s]\n",
      "34.1MB [00:03, 11.6MB/s]\n",
      "35.7MB [00:03, 11.6MB/s]\n",
      "37.0MB [00:03, 11.8MB/s]\n",
      "38.6MB [00:03, 11.2MB/s]\n",
      "40.1MB [00:03, 11.5MB/s]\n",
      "41.7MB [00:03, 11.7MB/s]\n",
      "43.3MB [00:03, 11.1MB/s]\n",
      "44.9MB [00:03, 11.5MB/s]\n",
      "46.1MB [00:04, 11.3MB/s]\n",
      "47.6MB [00:04, 12.1MB/s]\n",
      "49.2MB [00:04, 11.4MB/s]\n",
      "50.8MB [00:04, 12.2MB/s]\n",
      "52.3MB [00:04, 11.2MB/s]\n",
      "53.9MB [00:04, 11.9MB/s]\n",
      "55.1MB [00:04, 11.2MB/s]\n",
      "56.7MB [00:04, 11.6MB/s]\n",
      "58.3MB [00:05, 11.4MB/s]\n",
      "59.8MB [00:05, 11.4MB/s]\n",
      "61.4MB [00:05, 12.1MB/s]\n",
      "63.0MB [00:05, 11.8MB/s]\n",
      "64.5MB [00:05, 11.7MB/s]\n",
      "66.1MB [00:05, 11.1MB/s]\n",
      "67.7MB [00:05, 11.7MB/s]\n",
      "69.2MB [00:06, 11.4MB/s]\n",
      "70.8MB [00:06, 11.8MB/s]\n",
      "72.3MB [00:06, 11.6MB/s]\n",
      "73.8MB [00:06, 11.2MB/s]\n",
      "75.4MB [00:06, 12.0MB/s]\n",
      "76.9MB [00:06, 11.4MB/s]\n",
      "78.2MB [00:06, 11.0MB/s]\n",
      "79.8MB [00:06, 11.1MB/s]\n",
      "81.4MB [00:07, 11.9MB/s]\n",
      "82.8MB [00:07, 11.9MB/s]\n",
      "82.8MB [00:07, 11.5MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Rd0R_nRCrbjEdpOwq6XwZAktvugiBvmu\n",
      "To: C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\config_vocoder.json\n",
      "\n",
      "  0%|          | 0.00/6.76k [00:00<?, ?B/s]\n",
      "100%|##########| 6.76k/6.76k [00:00<?, ?B/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=11oY3Tv0kQtxK_JPgxrfesa99maVXHNxU\n",
      "To: C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\scale_stats.npy\n",
      "\n",
      "  0%|          | 0.00/10.5k [00:00<?, ?B/s]\n",
      "100%|##########| 10.5k/10.5k [00:00<?, ?B/s]\n",
      "fatal: destination path 'TTS' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1dntzjWFg7ufWaTaFy80nRz-Tu02xWZos -O tts_model.pth.tar\n",
    "!gdown --id 18CQ6G6tBEOfvCHlPqP8EBI4xWbrr9dBc -O config.json\n",
    "!gdown --id 1Ty5DZdOc0F7OTGj9oJThYbL5iVu_2G0K -O vocoder_model.pth.tar\n",
    "!gdown --id 1Rd0R_nRCrbjEdpOwq6XwZAktvugiBvmu -O config_vocoder.json\n",
    "!gdown --id 11oY3Tv0kQtxK_JPgxrfesa99maVXHNxU -O scale_stats.npy\n",
    "\n",
    "! sudo apt-get install espeak\n",
    "!git clone https://github.com/coqui-ai/TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38a84ff8",
   "metadata": {
    "id": "Mr5AvZq3EI8o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\TTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: switching to 'b1935c97'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at b1935c9 update server to enable native vocoder inference and remove pwgan support\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from -r requirements.txt (line 1)) (1.20.2)\n",
      "Requirement already satisfied: torch>=1.5 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from -r requirements.txt (line 2)) (1.8.1)\n",
      "Requirement already satisfied: librosa>=0.5.1 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from -r requirements.txt (line 3)) (0.8.0)\n",
      "Collecting Unidecode>=0.4.20\n",
      "  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.2-py2.py3-none-any.whl (120 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.4.1-cp38-cp38-win_amd64.whl (7.1 MB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from -r requirements.txt (line 8)) (8.2.0)\n",
      "Collecting flask\n",
      "  Using cached Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from -r requirements.txt (line 10)) (1.6.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from -r requirements.txt (line 11)) (4.49.0)\n",
      "Requirement already satisfied: soundfile in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from -r requirements.txt (line 12)) (0.10.3.post1)\n",
      "Collecting phonemizer\n",
      "  Downloading phonemizer-2.2.2-py3-none-any.whl (49 kB)\n",
      "Collecting bokeh==1.4.0\n",
      "  Downloading bokeh-1.4.0.tar.gz (32.4 MB)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from bokeh==1.4.0->-r requirements.txt (line 14)) (1.15.0)\n",
      "Collecting PyYAML>=3.10\n",
      "  Using cached PyYAML-5.4.1-cp38-cp38-win_amd64.whl (213 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from bokeh==1.4.0->-r requirements.txt (line 14)) (2.8.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from bokeh==1.4.0->-r requirements.txt (line 14)) (2.11.3)\n",
      "Requirement already satisfied: packaging>=16.8 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from bokeh==1.4.0->-r requirements.txt (line 14)) (20.9)\n",
      "Requirement already satisfied: tornado>=4.3 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from bokeh==1.4.0->-r requirements.txt (line 14)) (6.1)\n",
      "Requirement already satisfied: audioread>=2.0.0 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from librosa>=0.5.1->-r requirements.txt (line 3)) (2.1.9)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from librosa>=0.5.1->-r requirements.txt (line 3)) (0.2.2)\n",
      "Requirement already satisfied: numba>=0.43.0 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from librosa>=0.5.1->-r requirements.txt (line 3)) (0.53.1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from librosa>=0.5.1->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from librosa>=0.5.1->-r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from librosa>=0.5.1->-r requirements.txt (line 3)) (5.0.3)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from librosa>=0.5.1->-r requirements.txt (line 3)) (0.24.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from soundfile->-r requirements.txt (line 12)) (1.14.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from torch>=1.5->-r requirements.txt (line 2)) (3.7.4.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 12)) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from Jinja2>=2.7->bokeh==1.4.0->-r requirements.txt (line 14)) (1.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from numba>=0.43.0->librosa>=0.5.1->-r requirements.txt (line 3)) (52.0.0.post20210125)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from numba>=0.43.0->librosa>=0.5.1->-r requirements.txt (line 3)) (0.36.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from packaging>=16.8->bokeh==1.4.0->-r requirements.txt (line 14)) (2.4.7)\n",
      "Requirement already satisfied: requests in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from pooch>=1.0->librosa>=0.5.1->-r requirements.txt (line 3)) (2.25.1)\n",
      "Requirement already satisfied: appdirs in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from pooch>=1.0->librosa>=0.5.1->-r requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.5.1->-r requirements.txt (line 3)) (2.1.0)\n",
      "Collecting Werkzeug>=0.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from flask->-r requirements.txt (line 9)) (7.1.2)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Using cached itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.1-cp38-cp38-win_amd64.whl (51 kB)\n",
      "Collecting segments\n",
      "  Downloading segments-2.2.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: attrs>=18.1 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from phonemizer->-r requirements.txt (line 13)) (20.3.0)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Downloading protobuf-3.15.7-py2.py3-none-any.whl (173 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.28.0-py2.py3-none-any.whl (136 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.36.1-cp38-cp38-win_amd64.whl (3.0 MB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from tensorboard->-r requirements.txt (line 5)) (0.36.2)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from requests->pooch>=1.0->librosa>=0.5.1->-r requirements.txt (line 3)) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from requests->pooch>=1.0->librosa>=0.5.1->-r requirements.txt (line 3)) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from requests->pooch>=1.0->librosa>=0.5.1->-r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from requests->pooch>=1.0->librosa>=0.5.1->-r requirements.txt (line 3)) (2.10)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting csvw>=1.5.6\n",
      "  Downloading csvw-1.10.1-py2.py3-none-any.whl (34 kB)\n",
      "Collecting clldutils>=1.7.3\n",
      "  Downloading clldutils-3.7.0-py2.py3-none-any.whl (190 kB)\n",
      "Requirement already satisfied: regex in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from segments->phonemizer->-r requirements.txt (line 13)) (2021.4.4)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-4.8.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting isodate\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting uritemplate>=3.0.0\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Collecting rfc3986\n",
      "  Downloading rfc3986-1.4.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages (from colorlog->clldutils>=1.7.3->segments->phonemizer->-r requirements.txt (line 13)) (0.4.4)\n",
      "Building wheels for collected packages: bokeh\n",
      "  Building wheel for bokeh (setup.py): started\n",
      "  Building wheel for bokeh (setup.py): finished with status 'done'\n",
      "  Created wheel for bokeh: filename=bokeh-1.4.0-py3-none-any.whl size=23689215 sha256=b814de4713f33918013c7870a8329e165acad39f48fcf64091a09b7148f53e5e\n",
      "  Stored in directory: c:\\users\\r2q2\\appdata\\local\\pip\\cache\\wheels\\4a\\79\\96\\e953cfb5c24da5e5e03eb1ecb280ca88dce65661fb4d38c7b5\n",
      "Successfully built bokeh\n",
      "Installing collected packages: uritemplate, rfc3986, pyasn1, isodate, tabulate, rsa, pyasn1-modules, oauthlib, csvw, colorlog, cachetools, requests-oauthlib, google-auth, clldutils, Werkzeug, tensorboard-plugin-wit, segments, PyYAML, protobuf, markdown, kiwisolver, itsdangerous, grpcio, google-auth-oauthlib, cycler, absl-py, Unidecode, tensorboardX, tensorboard, phonemizer, matplotlib, flask, bokeh\n",
      "Successfully installed PyYAML-5.4.1 Unidecode-1.2.0 Werkzeug-1.0.1 absl-py-0.12.0 bokeh-1.4.0 cachetools-4.2.1 clldutils-3.7.0 colorlog-4.8.0 csvw-1.10.1 cycler-0.10.0 flask-1.1.2 google-auth-1.28.0 google-auth-oauthlib-0.4.4 grpcio-1.36.1 isodate-0.6.0 itsdangerous-1.1.0 kiwisolver-1.3.1 markdown-3.3.4 matplotlib-3.4.1 oauthlib-3.1.0 phonemizer-2.2.2 protobuf-3.15.7 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rfc3986-1.4.0 rsa-4.7.2 segments-2.2.0 tabulate-0.8.9 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorboardX-2.2 uritemplate-3.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: install_lib: 'temp_build' does not exist -- no Python modules to install\n",
      "\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "librosa.util.__pycache__.deprecation.cpython-38: module MAY be using inspect.stack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating tts_namespace\\TTS.egg-info\n",
      "writing tts_namespace\\TTS.egg-info\\PKG-INFO\n",
      "writing dependency_links to tts_namespace\\TTS.egg-info\\dependency_links.txt\n",
      "writing entry points to tts_namespace\\TTS.egg-info\\entry_points.txt\n",
      "writing requirements to tts_namespace\\TTS.egg-info\\requires.txt\n",
      "writing top-level names to tts_namespace\\TTS.egg-info\\top_level.txt\n",
      "writing manifest file 'tts_namespace\\TTS.egg-info\\SOURCES.txt'\n",
      "reading manifest file 'tts_namespace\\TTS.egg-info\\SOURCES.txt'\n",
      "writing manifest file 'tts_namespace\\TTS.egg-info\\SOURCES.txt'\n",
      "installing library code to build\\bdist.win-amd64\\egg\n",
      "running install_lib\n",
      "creating build\n",
      "creating build\\bdist.win-amd64\n",
      "creating build\\bdist.win-amd64\\egg\n",
      "creating build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying tts_namespace\\TTS.egg-info\\PKG-INFO -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying tts_namespace\\TTS.egg-info\\SOURCES.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying tts_namespace\\TTS.egg-info\\dependency_links.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying tts_namespace\\TTS.egg-info\\entry_points.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying tts_namespace\\TTS.egg-info\\requires.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying tts_namespace\\TTS.egg-info\\top_level.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "creating dist\n",
      "creating 'dist\\TTS-0.0.3+b1935c9-py3.8.egg' and adding 'build\\bdist.win-amd64\\egg' to it\n",
      "removing 'build\\bdist.win-amd64\\egg' (and everything under it)\n",
      "Processing TTS-0.0.3+b1935c9-py3.8.egg\n",
      "Copying TTS-0.0.3+b1935c9-py3.8.egg to c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Adding TTS 0.0.3+b1935c9 to easy-install.pth file\n",
      "Installing tts-server-script.py script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "Installing tts-server.exe script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "\n",
      "Installed c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\\tts-0.0.3+b1935c9-py3.8.egg\n",
      "Processing dependencies for TTS==0.0.3+b1935c9\n",
      "Searching for attrdict\n",
      "Reading https://pypi.org/simple/attrdict/\n",
      "Downloading https://files.pythonhosted.org/packages/ef/97/28fe7e68bc7adfce67d4339756e85e9fcf3c6fd7f0c0781695352b70472c/attrdict-2.0.1-py2.py3-none-any.whl#sha256=9432e3498c74ff7e1b20b3d93b45d766b71cbffa90923496f82c4ae38b92be34\n",
      "Best match: attrdict 2.0.1\n",
      "Processing attrdict-2.0.1-py2.py3-none-any.whl\n",
      "Installing attrdict-2.0.1-py2.py3-none-any.whl to c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Adding attrdict 2.0.1 to easy-install.pth file\n",
      "\n",
      "Installed c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\\attrdict-2.0.1-py3.8.egg\n",
      "Searching for unidecode==0.4.20\n",
      "Reading https://pypi.org/simple/unidecode/\n",
      "Downloading https://files.pythonhosted.org/packages/c3/6f/05f5deb753d0594583aa1cc0d2fe9d631d9a00e9b28d0da49f8d3763755b/Unidecode-0.04.20-py2.py3-none-any.whl#sha256=eedac7bfd886f43484787206f6a141b232e2b2a58652c54d06499b187fd84660\n",
      "Best match: Unidecode 0.4.20\n",
      "Processing Unidecode-0.04.20-py2.py3-none-any.whl\n",
      "Installing Unidecode-0.04.20-py2.py3-none-any.whl to c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Adding Unidecode 0.4.20 to easy-install.pth file\n",
      "Installing unidecode-script.py script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "Installing unidecode.exe script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "\n",
      "Installed c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\\unidecode-0.4.20-py3.8.egg\n",
      "Searching for librosa==0.6.2\n",
      "Reading https://pypi.org/simple/librosa/\n",
      "Downloading https://files.pythonhosted.org/packages/09/b4/5b411f19de48f8fc1a0ff615555aa9124952e4156e94d4803377e50cfa4c/librosa-0.6.2.tar.gz#sha256=2aa868b8aade749b9904eeb7034fcf44115601c367969b6d01f5e1b4b9b6031d\n",
      "Best match: librosa 0.6.2\n",
      "Processing librosa-0.6.2.tar.gz\n",
      "Writing C:\\Users\\r2q2\\AppData\\Local\\Temp\\easy_install-f5zdwn1k\\librosa-0.6.2\\setup.cfg\n",
      "Running librosa-0.6.2\\setup.py -q bdist_egg --dist-dir C:\\Users\\r2q2\\AppData\\Local\\Temp\\easy_install-f5zdwn1k\\librosa-0.6.2\\egg-dist-tmp-4quwx7bm\n",
      "creating c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\\librosa-0.6.2-py3.8.egg\n",
      "Extracting librosa-0.6.2-py3.8.egg to c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Adding librosa 0.6.2 to easy-install.pth file\n",
      "\n",
      "Installed c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\\librosa-0.6.2-py3.8.egg\n",
      "Searching for phonemizer==2.2.2\n",
      "Best match: phonemizer 2.2.2\n",
      "Adding phonemizer 2.2.2 to easy-install.pth file\n",
      "Installing phonemize-script.py script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "Installing phonemize.exe script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for SoundFile==0.10.3.post1\n",
      "Best match: SoundFile 0.10.3.post1\n",
      "Adding SoundFile 0.10.3.post1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for bokeh==1.4.0\n",
      "Best match: bokeh 1.4.0\n",
      "Adding bokeh 1.4.0 to easy-install.pth file\n",
      "Installing bokeh-script.py script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "Installing bokeh.exe script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for tqdm==4.49.0\n",
      "Best match: tqdm 4.49.0\n",
      "Adding tqdm 4.49.0 to easy-install.pth file\n",
      "Installing tqdm-script.py script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "Installing tqdm.exe script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for Flask==1.1.2\n",
      "Best match: Flask 1.1.2\n",
      "Adding Flask 1.1.2 to easy-install.pth file\n",
      "Installing flask-script.py script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "Installing flask.exe script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for Pillow==8.2.0\n",
      "Best match: Pillow 8.2.0\n",
      "Adding Pillow 8.2.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for matplotlib==3.4.1\n",
      "Best match: matplotlib 3.4.1\n",
      "Adding matplotlib 3.4.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for tensorboardX==2.2\n",
      "Best match: tensorboardX 2.2\n",
      "Adding tensorboardX 2.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for numpy==1.20.2\n",
      "Best match: numpy 1.20.2\n",
      "Adding numpy 1.20.2 to easy-install.pth file\n",
      "Installing f2py-script.py script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "Installing f2py.exe script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for torch==1.8.1\n",
      "Best match: torch 1.8.1\n",
      "Adding torch 1.8.1 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx-script.py script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "Installing convert-caffe2-to-onnx.exe script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "Installing convert-onnx-to-caffe2-script.py script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "Installing convert-onnx-to-caffe2.exe script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for scipy==1.6.2\n",
      "Best match: scipy 1.6.2\n",
      "Adding scipy 1.6.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for attrs==20.3.0\n",
      "Best match: attrs 20.3.0\n",
      "Adding attrs 20.3.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for segments==2.2.0\n",
      "Best match: segments 2.2.0\n",
      "Adding segments 2.2.0 to easy-install.pth fileC:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\n",
      "Installing segments-script.py script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "\n",
      "Installing segments.exe script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for joblib==1.0.1\n",
      "Best match: joblib 1.0.1\n",
      "Adding joblib 1.0.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for cffi==1.14.5\n",
      "Best match: cffi 1.14.5\n",
      "Adding cffi 1.14.5 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for tornado==6.1\n",
      "Best match: tornado 6.1\n",
      "Adding tornado 6.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for packaging==20.9\n",
      "Best match: packaging 20.9\n",
      "Adding packaging 20.9 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for python-dateutil==2.8.1\n",
      "Best match: python-dateutil 2.8.1\n",
      "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for six==1.15.0\n",
      "Best match: six 1.15.0\n",
      "Adding six 1.15.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for Jinja2==2.11.3\n",
      "Best match: Jinja2 2.11.3\n",
      "Adding Jinja2 2.11.3 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for PyYAML==5.4.1\n",
      "Best match: PyYAML 5.4.1\n",
      "Adding PyYAML 5.4.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for itsdangerous==1.1.0\n",
      "Best match: itsdangerous 1.1.0\n",
      "Adding itsdangerous 1.1.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for Werkzeug==1.0.1\n",
      "Best match: Werkzeug 1.0.1\n",
      "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for click==7.1.2\n",
      "Best match: click 7.1.2\n",
      "Adding click 7.1.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for pyparsing==2.4.7\n",
      "Best match: pyparsing 2.4.7\n",
      "Adding pyparsing 2.4.7 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for cycler==0.10.0\n",
      "Best match: cycler 0.10.0\n",
      "Adding cycler 0.10.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for kiwisolver==1.3.1\n",
      "Best match: kiwisolver 1.3.1\n",
      "Adding kiwisolver 1.3.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for protobuf==3.15.7\n",
      "Best match: protobuf 3.15.7\n",
      "Adding protobuf 3.15.7 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for numba==0.53.1\n",
      "Best match: numba 0.53.1\n",
      "Adding numba 0.53.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for resampy==0.2.2\n",
      "Best match: resampy 0.2.2\n",
      "Adding resampy 0.2.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for decorator==5.0.3\n",
      "Best match: decorator 5.0.3\n",
      "Adding decorator 5.0.3 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for scikit-learn==0.24.1\n",
      "Best match: scikit-learn 0.24.1\n",
      "Adding scikit-learn 0.24.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for audioread==2.1.9\n",
      "Best match: audioread 2.1.9\n",
      "Adding audioread 2.1.9 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for typing-extensions==3.7.4.3\n",
      "Best match: typing-extensions 3.7.4.3\n",
      "Adding typing-extensions 3.7.4.3 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for csvw==1.10.1\n",
      "Best match: csvw 1.10.1\n",
      "Adding csvw 1.10.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for clldutils==3.7.0\n",
      "Best match: clldutils 3.7.0\n",
      "Adding clldutils 3.7.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for regex==2021.4.4\n",
      "Best match: regex 2021.4.4\n",
      "Adding regex 2021.4.4 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for pycparser==2.20\n",
      "Best match: pycparser 2.20\n",
      "Adding pycparser 2.20 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for MarkupSafe==1.1.1\n",
      "Best match: MarkupSafe 1.1.1\n",
      "Adding MarkupSafe 1.1.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for llvmlite==0.36.0\n",
      "Best match: llvmlite 0.36.0\n",
      "Adding llvmlite 0.36.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for setuptools==52.0.0.post20210125\n",
      "Best match: setuptools 52.0.0.post20210125\n",
      "Adding setuptools 52.0.0.post20210125 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for threadpoolctl==2.1.0\n",
      "Best match: threadpoolctl 2.1.0\n",
      "Adding threadpoolctl 2.1.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for uritemplate==3.0.1\n",
      "Best match: uritemplate 3.0.1\n",
      "Adding uritemplate 3.0.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for isodate==0.6.0\n",
      "Best match: isodate 0.6.0\n",
      "Adding isodate 0.6.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for rfc3986==1.4.0\n",
      "Best match: rfc3986 1.4.0\n",
      "Adding rfc3986 1.4.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for tabulate==0.8.9\n",
      "Best match: tabulate 0.8.9\n",
      "Adding tabulate 0.8.9 to easy-install.pth file\n",
      "Installing tabulate-script.py script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "Installing tabulate.exe script to C:\\Users\\r2q2\\Anaconda3\\envs\\saati_twitch\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for colorlog==4.8.0\n",
      "Best match: colorlog 4.8.0\n",
      "Adding colorlog 4.8.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Searching for colorama==0.4.4\n",
      "Best match: colorama 0.4.4\n",
      "Adding colorama 0.4.4 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\anaconda3\\envs\\saati_twitch\\lib\\site-packages\n",
      "Finished processing dependencies for TTS==0.0.3+b1935c9\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'inflect'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2ef1bc0de41f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msetup_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbols\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msymbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphonemes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAudioProcessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynthesis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msynthesis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\opt\\Saati_to_commit\\notebooks\\TTS\\utils\\text\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mphonemizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mphonemizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphonemize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mphonemize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcleaners\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbols\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphonemes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_phoneme_punctuations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_bos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0m_eos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\opt\\Saati_to_commit\\notebooks\\TTS\\utils\\text\\cleaners.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0munidecode\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0munidecode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnumber_norm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnormalize_numbers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Regular expression matching whitespace:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\opt\\Saati_to_commit\\notebooks\\TTS\\utils\\text\\number_norm.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;34m\"\"\" from https://github.com/keithito/tacotron \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0minflect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'inflect'"
     ]
    }
   ],
   "source": [
    "\n",
    "%cd TTS\n",
    "!git checkout b1935c97\n",
    "!pip install -r requirements.txt\n",
    "!python setup.py install\n",
    "%cd ..\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import IPython\n",
    "\n",
    "from TTS.utils.generic_utils import setup_model\n",
    "from TTS.utils.io import load_config\n",
    "from TTS.utils.text.symbols import symbols, phonemes\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from TTS.utils.synthesis import synthesis\n",
    "from TTS.vocoder.utils.generic_utils import setup_generator\n",
    "\n",
    "# runtime settings\n",
    "use_cuda = False\n",
    "# model paths\n",
    "TTS_MODEL = \"tts_model.pth.tar\"\n",
    "TTS_CONFIG = \"config.json\"\n",
    "VOCODER_MODEL = \"vocoder_model.pth.tar\"\n",
    "VOCODER_CONFIG = \"config_vocoder.json\"\n",
    "# load configs\n",
    "TTS_CONFIG = load_config(TTS_CONFIG)\n",
    "VOCODER_CONFIG = load_config(VOCODER_CONFIG)\n",
    "# load the audio processor\n",
    "ap = AudioProcessor(**TTS_CONFIG.audio)\n",
    "# LOAD TTS MODEL\n",
    "# multi speaker \n",
    "speaker_id = None\n",
    "speakers = []\n",
    "\n",
    "# load the model\n",
    "num_chars = len(phonemes) if TTS_CONFIG.use_phonemes else len(symbols)\n",
    "model = setup_model(num_chars, len(speakers), TTS_CONFIG)\n",
    "\n",
    "# load model state\n",
    "cp =  torch.load(TTS_MODEL, map_location=torch.device('cpu'))\n",
    "\n",
    "# load the model\n",
    "model.load_state_dict(cp['model'])\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "model.eval()\n",
    "\n",
    "# set model stepsize\n",
    "if 'r' in cp:\n",
    "    model.decoder.set_r(cp['r'])\n",
    "\n",
    "# LOAD VOCODER MODEL\n",
    "vocoder_model = setup_generator(VOCODER_CONFIG)\n",
    "vocoder_model.load_state_dict(torch.load(VOCODER_MODEL, map_location=\"cpu\")[\"model\"])\n",
    "vocoder_model.remove_weight_norm()\n",
    "vocoder_model.inference_padding = 0\n",
    "\n",
    "ap_vocoder = AudioProcessor(**VOCODER_CONFIG['audio'])    \n",
    "if use_cuda:\n",
    "    vocoder_model.cuda()\n",
    "vocoder_model.eval()\n",
    "\n",
    "def tts(model, text, CONFIG, use_cuda, ap, use_gl, figures=True):\n",
    "    t_1 = time.time()\n",
    "    waveform, alignment, mel_spec, mel_postnet_spec, stop_tokens, inputs = synthesis(model, text, CONFIG, use_cuda, ap, speaker_id, style_wav=None,\n",
    "                                                                             truncated=False, enable_eos_bos_chars=CONFIG.enable_eos_bos_chars)\n",
    "    # mel_postnet_spec = ap._denormalize(mel_postnet_spec.T)\n",
    "    if not use_gl:\n",
    "        waveform = vocoder_model.inference(torch.FloatTensor(mel_postnet_spec.T).unsqueeze(0))\n",
    "        waveform = waveform.flatten()\n",
    "    if use_cuda:\n",
    "        waveform = waveform.cpu()\n",
    "    waveform = waveform.numpy()\n",
    "    rtf = (time.time() - t_1) / (len(waveform) / ap.sample_rate)\n",
    "    tps = (time.time() - t_1) / len(waveform)\n",
    "    print(waveform.shape)\n",
    "    print(\" > Run-time: {}\".format(time.time() - t_1))\n",
    "    print(\" > Real-time factor: {}\".format(rtf))\n",
    "    print(\" > Time per step: {}\".format(tps))\n",
    "    IPython.display.display(IPython.display.Audio(waveform, rate=CONFIG.audio['sample_rate']))  \n",
    "    return alignment, mel_postnet_spec, stop_tokens, waveform\n",
    "\n",
    "sentence =  \"Bill got in the habit of asking himself “Is that thought true?” and if he wasn’t absolutely certain it was, he just let it go.\"\n",
    "align, spec, stop_tokens, wav = tts(model, sentence, TTS_CONFIG, use_cuda, ap, use_gl=False, figures=True)\n",
    "#align, spec, stop_tokens, wav = tts(model, blenderbot400M(transcription)[0], TTS_CONFIG, use_cuda, ap, use_gl=False, figures=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19b17b3",
   "metadata": {
    "id": "zs_dYZWzc2d9"
   },
   "outputs": [],
   "source": [
    "!pip install scipy\n",
    "from scipy.io.wavfile import write\n",
    "samplerate = 22050; #fs = 100\n",
    "write('/content/test.wav', samplerate, wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b0bb4",
   "metadata": {
    "id": "4lNScvXmex0g"
   },
   "outputs": [],
   "source": [
    "print('Git clone project and install requirements...')\n",
    "!git clone https://github.com/yzhou359/MakeItTalk &> /dev/null\n",
    "%cd MakeItTalk/\n",
    "!export PYTHONPATH=/content/MakeItTalk:$PYTHONPATH\n",
    "!pip install -r requirements.txt &> /dev/null\n",
    "!pip install tensorboardX &> /dev/null\n",
    "!mkdir examples/dump\n",
    "!mkdir examples/ckpt\n",
    "!pip install gdown &> /dev/null\n",
    "print('Done!')\n",
    "print('Download pre-trained models...')\n",
    "!gdown -O examples/ckpt/ckpt_autovc.pth https://drive.google.com/uc?id=1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x\n",
    "!gdown -O examples/ckpt/ckpt_content_branch.pth https://drive.google.com/uc?id=1r3bfEvTVl6pCNw5xwUhEglwDHjWtAqQp\n",
    "!gdown -O examples/ckpt/ckpt_speaker_branch.pth https://drive.google.com/uc?id=1rV0jkyDqPW-aDJcj7xSO6Zt1zSXqn1mu\n",
    "!gdown -O examples/ckpt/ckpt_116_i2i_comb.pth https://drive.google.com/uc?id=1i2LJXKp-yWKIEEgJ7C6cE3_2NirfY_0a\n",
    "!gdown -O examples/dump/emb.pickle https://drive.google.com/uc?id=18-0CYl5E6ungS3H4rRSHjfYvvm-WwjTI\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee2ad0",
   "metadata": {
    "id": "iRZ-NZypOuIN"
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"Choose the image name to animate: (saved in folder 'examples/')\")\n",
    "img_list = glob.glob1('examples', '*.jpg')\n",
    "img_list.sort()\n",
    "img_list = [item.split('.')[0] for item in img_list]\n",
    "default_head_name = widgets.Dropdown(options=img_list, value='paint_boy')\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        plt.imshow(plt.imread('examples/{}.jpg'.format(default_head_name.value)))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "default_head_name.observe(on_change)\n",
    "display(default_head_name)\n",
    "plt.imshow(plt.imread('examples/{}.jpg'.format(default_head_name.value)))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd034582",
   "metadata": {
    "id": "mkH0WKbDhO5t"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@markdown # Animation Controllers\n",
    "#@markdown Amplify the lip motion in horizontal direction\n",
    "AMP_LIP_SHAPE_X = 2.8 #@param {type:\"slider\", min:0.5, max:5.0, step:0.1}\n",
    "\n",
    "#@markdown Amplify the lip motion in vertical direction\n",
    "AMP_LIP_SHAPE_Y = 2 #@param {type:\"slider\", min:0.5, max:5.0, step:0.1}\n",
    "\n",
    "#@markdown Amplify the head pose motion (usually smaller than 1.0, put it to 0. for a static head pose)\n",
    "AMP_HEAD_POSE_MOTION = 0.35 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
    "\n",
    "#@markdown Add naive eye blink\n",
    "ADD_NAIVE_EYE = True  #@param [\"False\", \"True\"] {type:\"raw\"}\n",
    "\n",
    "#@markdown If your image has an opened mouth, put this as True, else False\n",
    "CLOSE_INPUT_FACE_MOUTH = False  #@param [\"False\", \"True\"] {type:\"raw\"}          \n",
    "\n",
    "\n",
    "#@markdown # Landmark Adjustment\n",
    "\n",
    "#@markdown Adjust upper lip thickness (postive value means thicker)\n",
    "UPPER_LIP_ADJUST = -1 #@param {type:\"slider\", min:-3.0, max:3.0, step:1.0}\n",
    "\n",
    "#@markdown Adjust lower lip thickness (postive value means thicker)\n",
    "LOWER_LIP_ADJUST = -1 #@param {type:\"slider\", min:-3.0, max:3.0, step:1.0}\n",
    "\n",
    "#@markdown Adjust static lip width (in multipication)\n",
    "LIP_WIDTH_ADJUST = 1.0 #@param {type:\"slider\", min:0.8, max:1.2, step:0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4214f7",
   "metadata": {
    "id": "BFajpH1aOyjs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4111c",
   "metadata": {
    "id": "vAfQWE6jO1IF"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"thirdparty/AdaptiveWingLoss\")\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "from src.approaches.train_image_translation import Image_translation_block\n",
    "import torch\n",
    "import pickle\n",
    "import face_alignment\n",
    "from src.autovc.AutoVC_mel_Convertor_retrain_version import AutoVC_mel_Convertor\n",
    "import shutil\n",
    "import time\n",
    "import util.utils as util\n",
    "from scipy.signal import savgol_filter\n",
    "from src.approaches.train_audio2landmark import Audio2landmark_model\n",
    "\n",
    "sys.stdout = open(os.devnull, 'a')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--jpg', type=str, default='{}.jpg'.format(default_head_name.value))\n",
    "parser.add_argument('--close_input_face_mouth', default=CLOSE_INPUT_FACE_MOUTH, action='store_true')\n",
    "parser.add_argument('--load_AUTOVC_name', type=str, default='examples/ckpt/ckpt_autovc.pth')\n",
    "parser.add_argument('--load_a2l_G_name', type=str, default='examples/ckpt/ckpt_speaker_branch.pth')\n",
    "parser.add_argument('--load_a2l_C_name', type=str, default='examples/ckpt/ckpt_content_branch.pth') #ckpt_audio2landmark_c.pth')\n",
    "parser.add_argument('--load_G_name', type=str, default='examples/ckpt/ckpt_116_i2i_comb.pth') #ckpt_image2image.pth') #ckpt_i2i_finetune_150.pth') #c\n",
    "parser.add_argument('--amp_lip_x', type=float, default=AMP_LIP_SHAPE_X)\n",
    "parser.add_argument('--amp_lip_y', type=float, default=AMP_LIP_SHAPE_Y)\n",
    "parser.add_argument('--amp_pos', type=float, default=AMP_HEAD_POSE_MOTION)\n",
    "parser.add_argument('--reuse_train_emb_list', type=str, nargs='+', default=[]) #  ['iWeklsXc0H8']) #['45hn7-LXDX8']) #['E_kmpT-EfOg']) #'iWeklsXc0H8', '29k8RtSUjE0', '45hn7-LXDX8',\n",
    "parser.add_argument('--add_audio_in', default=False, action='store_true')\n",
    "parser.add_argument('--comb_fan_awing', default=False, action='store_true')\n",
    "parser.add_argument('--output_folder', type=str, default='examples')\n",
    "parser.add_argument('--test_end2end', default=True, action='store_true')\n",
    "parser.add_argument('--dump_dir', type=str, default='', help='')\n",
    "parser.add_argument('--pos_dim', default=7, type=int)\n",
    "parser.add_argument('--use_prior_net', default=True, action='store_true')\n",
    "parser.add_argument('--transformer_d_model', default=32, type=int)\n",
    "parser.add_argument('--transformer_N', default=2, type=int)\n",
    "parser.add_argument('--transformer_heads', default=2, type=int)\n",
    "parser.add_argument('--spk_emb_enc_size', default=16, type=int)\n",
    "parser.add_argument('--init_content_encoder', type=str, default='')\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help='learning rate')\n",
    "parser.add_argument('--reg_lr', type=float, default=1e-6, help='weight decay')\n",
    "parser.add_argument('--write', default=False, action='store_true')\n",
    "parser.add_argument('--segment_batch_size', type=int, default=1, help='batch size')\n",
    "parser.add_argument('--emb_coef', default=3.0, type=float)\n",
    "parser.add_argument('--lambda_laplacian_smooth_loss', default=1.0, type=float)\n",
    "parser.add_argument('--use_11spk_only', default=False, action='store_true')\n",
    "parser.add_argument('-f')\n",
    "opt_parser = parser.parse_args()\n",
    "\n",
    "img = cv2.imread('examples/' + opt_parser.jpg)\n",
    "predictor = face_alignment.FaceAlignment(face_alignment.LandmarksType._3D, device='cpu', flip_input=True)\n",
    "shapes = predictor.get_landmarks(img)\n",
    "if (not shapes or len(shapes) != 1):\n",
    "    print('Cannot detect face landmarks. Exit.')\n",
    "    exit(-1)\n",
    "shape_3d = shapes[0]\n",
    "if(opt_parser.close_input_face_mouth):\n",
    "    util.close_input_face_mouth(shape_3d)\n",
    "shape_3d[48:, 0] = (shape_3d[48:, 0] - np.mean(shape_3d[48:, 0])) * LIP_WIDTH_ADJUST + np.mean(shape_3d[48:, 0]) # wider lips\n",
    "shape_3d[49:54, 1] -= UPPER_LIP_ADJUST           # thinner upper lip\n",
    "shape_3d[55:60, 1] += LOWER_LIP_ADJUST           # thinner lower lip\n",
    "shape_3d[[37,38,43,44], 1] -=2.    # larger eyes\n",
    "shape_3d[[40,41,46,47], 1] +=2.    # larger eyes\n",
    "shape_3d, scale, shift = util.norm_input_face(shape_3d)\n",
    "\n",
    "print(\"Loaded Image...\", file=sys.stderr)\n",
    "\n",
    "au_data = []\n",
    "au_emb = []\n",
    "ains = glob.glob1('examples', '*.wav')\n",
    "ains = [item for item in ains if item is not 'tmp.wav']\n",
    "ains.sort()\n",
    "for ain in ains:\n",
    "    os.system('ffmpeg -y -loglevel error -i examples/{} -ar 16000 examples/tmp.wav'.format(ain))\n",
    "    shutil.copyfile('examples/tmp.wav', 'examples/{}'.format(ain))\n",
    "\n",
    "    # au embedding\n",
    "    from thirdparty.resemblyer_util.speaker_emb import get_spk_emb\n",
    "    me, ae = get_spk_emb('examples/{}'.format(ain))\n",
    "    au_emb.append(me.reshape(-1))\n",
    "\n",
    "    print('Processing audio file', ain)\n",
    "    c = AutoVC_mel_Convertor('examples')\n",
    "\n",
    "    au_data_i = c.convert_single_wav_to_autovc_input(audio_filename=os.path.join('examples', ain),\n",
    "           autovc_model_path=opt_parser.load_AUTOVC_name)\n",
    "    au_data += au_data_i\n",
    "if(os.path.isfile('examples/tmp.wav')):\n",
    "    os.remove('examples/tmp.wav')\n",
    "\n",
    "print(\"Loaded audio...\", file=sys.stderr)\n",
    "\n",
    "# landmark fake placeholder\n",
    "fl_data = []\n",
    "rot_tran, rot_quat, anchor_t_shape = [], [], []\n",
    "for au, info in au_data:\n",
    "    au_length = au.shape[0]\n",
    "    fl = np.zeros(shape=(au_length, 68 * 3))\n",
    "    fl_data.append((fl, info))\n",
    "    rot_tran.append(np.zeros(shape=(au_length, 3, 4)))\n",
    "    rot_quat.append(np.zeros(shape=(au_length, 4)))\n",
    "    anchor_t_shape.append(np.zeros(shape=(au_length, 68 * 3)))\n",
    "\n",
    "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_fl.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_fl.pickle'))\n",
    "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_fl_interp.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_fl_interp.pickle'))\n",
    "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_au.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_au.pickle'))\n",
    "if (os.path.exists(os.path.join('examples', 'dump', 'random_val_gaze.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_gaze.pickle'))\n",
    "\n",
    "with open(os.path.join('examples', 'dump', 'random_val_fl.pickle'), 'wb') as fp:\n",
    "    pickle.dump(fl_data, fp)\n",
    "with open(os.path.join('examples', 'dump', 'random_val_au.pickle'), 'wb') as fp:\n",
    "    pickle.dump(au_data, fp)\n",
    "with open(os.path.join('examples', 'dump', 'random_val_gaze.pickle'), 'wb') as fp:\n",
    "    gaze = {'rot_trans':rot_tran, 'rot_quat':rot_quat, 'anchor_t_shape':anchor_t_shape}\n",
    "    pickle.dump(gaze, fp)\n",
    "\n",
    "model = Audio2landmark_model(opt_parser, jpg_shape=shape_3d)\n",
    "if(len(opt_parser.reuse_train_emb_list) == 0):\n",
    "    model.test(au_emb=au_emb)\n",
    "else:\n",
    "    model.test(au_emb=None)\n",
    "\n",
    "print(\"Audio->Landmark...\", file=sys.stderr)\n",
    "\n",
    "fls = glob.glob1('examples', 'pred_fls_*.txt')\n",
    "fls.sort()\n",
    "\n",
    "for i in range(0,len(fls)):\n",
    "    fl = np.loadtxt(os.path.join('examples', fls[i])).reshape((-1, 68,3))\n",
    "    fl[:, :, 0:2] = -fl[:, :, 0:2]\n",
    "    fl[:, :, 0:2] = fl[:, :, 0:2] / scale - shift\n",
    "\n",
    "    if (ADD_NAIVE_EYE):\n",
    "        fl = util.add_naive_eye(fl)\n",
    "\n",
    "    # additional smooth\n",
    "    fl = fl.reshape((-1, 204))\n",
    "    fl[:, :48 * 3] = savgol_filter(fl[:, :48 * 3], 15, 3, axis=0)\n",
    "    fl[:, 48*3:] = savgol_filter(fl[:, 48*3:], 5, 3, axis=0)\n",
    "    fl = fl.reshape((-1, 68, 3))\n",
    "\n",
    "    ''' STEP 6: Imag2image translation '''\n",
    "    model = Image_translation_block(opt_parser, single_test=True)\n",
    "    with torch.no_grad():\n",
    "        model.single_test(jpg=img, fls=fl, filename=fls[i], prefix=opt_parser.jpg.split('.')[0])\n",
    "        print('finish image2image gen')\n",
    "    os.remove(os.path.join('examples', fls[i]))\n",
    "\n",
    "    print(\"{} / {}: Landmark->Face...\".format(i+1, len(fls)), file=sys.stderr)\n",
    "print(\"Done!\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8cf32",
   "metadata": {
    "id": "bx83jnNsX7ts"
   },
   "outputs": [],
   "source": [
    "!pip freeze | cat > requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63bcfc2",
   "metadata": {
    "id": "07FWqzIJU5sy"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets==1.4.1\n",
    "!pip install transformers==4.4.2\n",
    "!pip install torchaudio\n",
    "!pip install librosa\n",
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7df918",
   "metadata": {
    "id": "ORtmDPR1bUmj"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "input_values = processor(ds[\"speech\"][0], return_tensors=\"pt\").input_values  # Batch size 1\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "\n",
    "# compute loss\n",
    "target_transcription = \"A MAN SAID TO THE UNIVERSE SIR I EXIST\"\n",
    "\n",
    "# wrap processor as target processor to encode labels\n",
    "with processor.as_target_processor():\n",
    "    labels = processor(transcription, return_tensors=\"pt\").input_ids\n",
    "\n",
    "loss = model(input_values, labels=labels).loss\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc34b40",
   "metadata": {
    "id": "iJvMnDnJY5-X"
   },
   "outputs": [],
   "source": [
    "def map_to_array(batch):\n",
    "     speech, _ = sf.read(batch[\"file\"])\n",
    "     batch[\"speech\"] = speech\n",
    "     return batch\n",
    "\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "input_values = processor(ds[\"speech\"][0], return_tensors=\"pt\").input_values  # Batch size 1\n",
    "hidden_states = model(input_values).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee3a72",
   "metadata": {
    "id": "zKC7LMMn7k7m"
   },
   "outputs": [],
   "source": [
    "#Chinese\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa744589",
   "metadata": {
    "id": "Vqws5RzBC9CH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50efc71",
   "metadata": {
    "id": "TO8kYeIGDcuT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e462af8e",
   "metadata": {
    "id": "YI6OI0m6B-X7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162e7e89",
   "metadata": {
    "id": "pz94In6nDwI3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca77c88",
   "metadata": {
    "id": "022dKBB5D5TY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3667c2",
   "metadata": {
    "id": "cICFsl8cEEOX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb0dfb",
   "metadata": {
    "id": "rJRqQhIAF1SJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a14e4",
   "metadata": {
    "id": "fm1m74gCFBHZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e42261e",
   "metadata": {
    "id": "5cyP1VFy9ZMa"
   },
   "outputs": [],
   "source": [
    "AUDIO_HTML = \"\"\"\n",
    "<script>\n",
    "var my_div = document.createElement(\"DIV\");\n",
    "var my_p = document.createElement(\"P\");\n",
    "var my_btn = document.createElement(\"BUTTON\");\n",
    "var t = document.createTextNode(\"Press to start recording\");\n",
    "\n",
    "my_btn.appendChild(t);\n",
    "//my_p.appendChild(my_btn);\n",
    "my_div.appendChild(my_btn);\n",
    "document.body.appendChild(my_div);\n",
    "\n",
    "var base64data = 0;\n",
    "var reader;\n",
    "var recorder, gumStream;\n",
    "var recordButton = my_btn;\n",
    "\n",
    "var handleSuccess = function(stream) {\n",
    "  gumStream = stream;\n",
    "  var options = {\n",
    "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
    "    mimeType : 'audio/webm;codecs=opus'\n",
    "    //mimeType : 'audio/webm;codecs=pcm'\n",
    "  };            \n",
    "  //recorder = new MediaRecorder(stream, options);\n",
    "  recorder = new MediaRecorder(stream);\n",
    "  recorder.ondataavailable = function(e) {            \n",
    "    var url = URL.createObjectURL(e.data);\n",
    "    var preview = document.createElement('audio');\n",
    "    preview.controls = true;\n",
    "    preview.src = url;\n",
    "    document.body.appendChild(preview);\n",
    "\n",
    "    reader = new FileReader();\n",
    "    reader.readAsDataURL(e.data); \n",
    "    reader.onloadend = function() {\n",
    "      base64data = reader.result;\n",
    "      //console.log(\"Inside FileReader:\" + base64data);\n",
    "    }\n",
    "  };\n",
    "  recorder.start();\n",
    "  };\n",
    "\n",
    "recordButton.innerText = \"Recording... press to stop\";\n",
    "\n",
    "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
    "\n",
    "function toggleRecording() {\n",
    "  if (recorder && recorder.state == \"recording\") {\n",
    "      recorder.stop();\n",
    "      gumStream.getAudioTracks()[0].stop();\n",
    "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
    "  }\n",
    "}\n",
    "\n",
    "// https://stackoverflow.com/a/951057\n",
    "function sleep(ms) {\n",
    "  return new Promise(resolve => setTimeout(resolve, ms));\n",
    "}\n",
    "\n",
    "var data = new Promise(resolve=>{\n",
    "//recordButton.addEventListener(\"click\", toggleRecording);\n",
    "recordButton.onclick = ()=>{\n",
    "toggleRecording()\n",
    "\n",
    "sleep(2000).then(() => {\n",
    "  // wait 2000ms for the data to be available...\n",
    "  // ideally this should use something like await...\n",
    "  //console.log(\"Inside data:\" + base64data)\n",
    "  resolve(base64data.toString())\n",
    "\n",
    "});\n",
    "\n",
    "}\n",
    "});\n",
    "      \n",
    "</script>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4063afe6",
   "metadata": {
    "id": "XtRvHu4J9iRx"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Audio\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "import wave\n",
    "from scipy.io.wavfile import read as wav_read\n",
    "import io\n",
    "import numpy as np\n",
    "import ffmpeg\n",
    "\n",
    "def write_wav(f, sr, x, normalized=False):\n",
    "    f = wave.open(f, \"wb\")\n",
    "    f.setnchannels(1)\n",
    "    f.setsampwidth(2)\n",
    "    f.setframerate(sr)\n",
    "    \n",
    "    wave_data = x.astype(np.short)\n",
    "    f.writeframes(wave_data.tobytes())\n",
    "    f.close()\n",
    "\n",
    "def get_audio():\n",
    "  global hnum\n",
    "\n",
    "  # call microphone\n",
    "  display(HTML(AUDIO_HTML))\n",
    "  data = eval_js(\"data\")\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "\n",
    "  process = (ffmpeg\n",
    "      .input('pipe:0')\n",
    "      .output('pipe:1', format='wav')\n",
    "      .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
    "  )\n",
    "  output, err = process.communicate(input=binary)\n",
    "\n",
    "  riff_chunk_size = len(output) - 8\n",
    "  # Break up the chunk size into four bytes, held in b.\n",
    "  q = riff_chunk_size\n",
    "  b = []\n",
    "  for i in range(4):\n",
    "      q, r = divmod(q, 256)\n",
    "      b.append(r)\n",
    "\n",
    "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
    "  riff = output[:4] + bytes(b) + output[8:]\n",
    "  sr, audio = wav_read(io.BytesIO(riff))\n",
    "  # save\n",
    "  human_sound_file = \"demo.wav\"\n",
    "  write_wav(human_sound_file, sr, audio)\n",
    "\n",
    "  return human_sound_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72c7f1",
   "metadata": {
    "id": "s8VfU0Ta9l2S"
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    Wav2Vec2ForCTC,\n",
    "    Wav2Vec2Processor,\n",
    ")\n",
    "import torch\n",
    "import re\n",
    "import sys\n",
    "\n",
    "model_name = \"voidful/wav2vec2-large-xlsr-53-hk\"\n",
    "device = \"cuda\"\n",
    "processor_name = \"voidful/wav2vec2-large-xlsr-53-hk\"\n",
    "\n",
    "chars_to_ignore_regex = r\"[¥•＂＃＄％＆＇（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､　、〃〈〉《》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏﹑﹔·'℃°•·．﹑︰〈〉─《﹖﹣﹂﹁﹔！？｡。＂＃＄％＆＇（）＊＋，﹐－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏.．!\\\"#$%&()*+,\\-.\\:;<=>?@\\[\\]\\\\\\/^_`{|}~]\"\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name).to(device)\n",
    "processor = Wav2Vec2Processor.from_pretrained(processor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4944ac48",
   "metadata": {
    "id": "QVjB-P1o9n_h"
   },
   "outputs": [],
   "source": [
    "resampler = torchaudio.transforms.Resample(orig_freq=48_000, new_freq=16_000)\n",
    "\n",
    "def load_file_to_data(file):\n",
    "    batch = {}\n",
    "    speech, _ = torchaudio.load(file)\n",
    "    batch[\"speech\"] = resampler.forward(speech.squeeze(0)).numpy()\n",
    "    batch[\"sampling_rate\"] = resampler.new_freq\n",
    "    return batch\n",
    "\n",
    "\n",
    "def predict(data):\n",
    "    features = processor(data[\"speech\"], sampling_rate=data[\"sampling_rate\"], padding=True, return_tensors=\"pt\")\n",
    "    input_values = features.input_values.to(device)\n",
    "    attention_mask = features.attention_mask.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values, attention_mask=attention_mask).logits\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    return processor.batch_decode(pred_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a9400",
   "metadata": {
    "id": "g_6MxboF9p8J"
   },
   "outputs": [],
   "source": [
    "get_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9fa91",
   "metadata": {
    "id": "5WiSh_md9sL_"
   },
   "outputs": [],
   "source": [
    "predict(load_file_to_data('./demo.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec6c7d3",
   "metadata": {
    "id": "cldcsU04-EBz"
   },
   "outputs": [],
   "source": [
    "!pip install mecab-python3\n",
    "!pip install unidic-lite\n",
    "!python -m unidic download\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "from datasets import load_dataset\n",
    "import MeCab\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import re\n",
    "\n",
    "# config\n",
    "wakati = MeCab.Tagger(\"-Owakati\")\n",
    "chars_to_ignore_regex = '[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\、\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\。\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\．\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\「\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\」\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\…\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\？\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\・]'\n",
    "\n",
    "# load data, processor and model\n",
    "test_dataset = load_dataset(\"common_voice\", \"ja\", split=\"test[:2%]\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"vumichien/wav2vec2-large-xlsr-japanese\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"vumichien/wav2vec2-large-xlsr-japanese\")\n",
    "resampler = lambda sr, y: librosa.resample(y.numpy().squeeze(), sr, 16_000)\n",
    "\n",
    "# Preprocessing the datasets.\n",
    "def speech_file_to_array_fn(batch):\n",
    "    batch[\"sentence\"] = wakati.parse(batch[\"sentence\"]).strip()\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex,'', batch[\"sentence\"]).strip()\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resampler(sampling_rate, speech_array).squeeze()\n",
    "    return batch\n",
    "test_dataset = test_dataset.map(speech_file_to_array_fn)\n",
    "inputs = processor(test_dataset[\"speech\"][:2], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "print(\"Prediction:\", processor.batch_decode(predicted_ids))\n",
    "print(\"Reference:\", test_dataset[\"sentence\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1785644b",
   "metadata": {
    "id": "ioPI9jML-MsD"
   },
   "outputs": [],
   "source": [
    "!pip install mecab-python3\n",
    "!pip install unidic-lite\n",
    "!python -m unidic download\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "import torchaudio\n",
    "from datasets import load_dataset, load_metric\n",
    "import MeCab\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import re\n",
    "\n",
    "#config\n",
    "wakati = MeCab.Tagger(\"-Owakati\")\n",
    "chars_to_ignore_regex = '[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\、\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\。\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\．\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\「\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\」\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\…\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\？\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\・]'\n",
    "\n",
    "# load data, processor and model\n",
    "test_dataset = load_dataset(\"common_voice\", \"ja\", split=\"test\")\n",
    "wer = load_metric(\"wer\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"vumichien/wav2vec2-large-xlsr-japanese\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"vumichien/wav2vec2-large-xlsr-japanese\")\n",
    "model.to(\"cuda\")\n",
    "resampler = lambda sr, y: librosa.resample(y.numpy().squeeze(), sr, 16_000)\n",
    "\n",
    "# Preprocessing the datasets.\n",
    "def speech_file_to_array_fn(batch):\n",
    "    batch[\"sentence\"] = wakati.parse(batch[\"sentence\"]).strip()\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex,'', batch[\"sentence\"]).strip()\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resampler(sampling_rate, speech_array).squeeze()\n",
    "    return batch\n",
    "test_dataset = test_dataset.map(speech_file_to_array_fn)\n",
    "\n",
    "# evaluate function\n",
    "def evaluate(batch):\n",
    "    inputs = processor(batch[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values.to(\"cuda\"), attention_mask=inputs.attention_mask.to(\"cuda\")).logits\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    batch[\"pred_strings\"] = processor.batch_decode(pred_ids)\n",
    "    return batch\n",
    "result = test_dataset.map(evaluate, batched=True, batch_size=8)\n",
    "print(\"WER: {:2f}\".format(100 * wer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f72d47",
   "metadata": {
    "id": "DC-iTg1F-uuj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943813bc",
   "metadata": {
    "id": "ULPfLNJP_fXm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "processor = Speech2Textprocessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"patrickvonplaten/librispeech_asr_dummy\",\n",
    "    \"clean\",\n",
    "    split=\"validation\"\n",
    ")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "input_features = processor(\n",
    "    ds[\"speech\"][0],\n",
    "    sampling_rate=16_000,\n",
    "    return_tensors=\"pt\"\n",
    ").input_features  # Batch size 1\n",
    "generated_ids = model.generate(input_ids=input_features)\n",
    "\n",
    "transcription = processor.batch_decode(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76edd9e2",
   "metadata": {
    "id": "IiEF9KFbK_gZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "processor = Speech2Textprocessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"patrickvonplaten/librispeech_asr_dummy\",\n",
    "    \"clean\",\n",
    "    split=\"validation\"\n",
    ")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "input_features = processor(\n",
    "    ds[\"speech\"][0],\n",
    "    sampling_rate=16_000,\n",
    "    return_tensors=\"pt\"\n",
    ").input_features  # Batch size 1\n",
    "generated_ids = model.generate(input_ids=input_features)\n",
    "\n",
    "transcription = processor.batch_decode(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58842c4b",
   "metadata": {
    "id": "BIf4Du5pLxQR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Twitch_integration_prototyping.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
