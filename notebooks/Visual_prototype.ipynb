{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "isolated-prerequisite",
   "metadata": {
    "id": "dwFXS0vUzsfO"
   },
   "source": [
    "# MakeItTalk + text to speech and speech recognition\n",
    "\n",
    "- included project setup + pretrained model download\n",
    "- provides step-by-step details\n",
    "- todo: tdlr version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-librarian",
   "metadata": {
    "id": "NVAYGCMEwDwB"
   },
   "source": [
    "Start make it talk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "national-netherlands",
   "metadata": {
    "id": "QVedbX194R-A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git clone project and install requirements...\n",
      "[WinError 2] The system cannot find the file specified: 'MakeItTalk/'\n",
      "C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "The syntax of the command is incorrect.\n",
      "The syntax of the command is incorrect.\n",
      "The syntax of the command is incorrect.\n",
      "The syntax of the command is incorrect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Download pre-trained models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x\n",
      "To: C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\examples\\ckpt\\ckpt_autovc.pth\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\\gdown.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\gdown\\cli.py\", line 99, in main\n",
      "    filename = download(\n",
      "  File \"c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\gdown\\download.py\", line 189, in download\n",
      "    f = open(tmp_file, \"wb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'examples/ckpt\\\\ckpt_autovc.pth2at0bpzmtmp'\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1r3bfEvTVl6pCNw5xwUhEglwDHjWtAqQp\n",
      "To: C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\examples\\ckpt\\ckpt_content_branch.pth\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\\gdown.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\gdown\\cli.py\", line 99, in main\n",
      "    filename = download(\n",
      "  File \"c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\gdown\\download.py\", line 189, in download\n",
      "    f = open(tmp_file, \"wb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'examples/ckpt\\\\ckpt_content_branch.pth4gdvj58qtmp'\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1rV0jkyDqPW-aDJcj7xSO6Zt1zSXqn1mu\n",
      "To: C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\examples\\ckpt\\ckpt_speaker_branch.pth\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\\gdown.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\gdown\\cli.py\", line 99, in main\n",
      "    filename = download(\n",
      "  File \"c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\gdown\\download.py\", line 189, in download\n",
      "    f = open(tmp_file, \"wb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'examples/ckpt\\\\ckpt_speaker_branch.pthob2_q5w7tmp'\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1i2LJXKp-yWKIEEgJ7C6cE3_2NirfY_0a\n",
      "To: C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\examples\\ckpt\\ckpt_116_i2i_comb.pth\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\\gdown.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\gdown\\cli.py\", line 99, in main\n",
      "    filename = download(\n",
      "  File \"c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\gdown\\download.py\", line 189, in download\n",
      "    f = open(tmp_file, \"wb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'examples/ckpt\\\\ckpt_116_i2i_comb.pthnvg3sckqtmp'\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=18-0CYl5E6ungS3H4rRSHjfYvvm-WwjTI\n",
      "To: C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\examples\\dump\\emb.pickle\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\\gdown.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\gdown\\cli.py\", line 99, in main\n",
      "    filename = download(\n",
      "  File \"c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\gdown\\download.py\", line 189, in download\n",
      "    f = open(tmp_file, \"wb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'examples/dump\\\\emb.picklewe383yz5tmp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May  8 18:58:15 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 461.92       Driver Version: 461.92       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX          WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 41%   43C    P8    13W / 280W |   6457MiB / 24576MiB |     19%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla M40 24GB      TCC  | 00000000:23:00.0 Off |                    0 |\n",
      "| N/A   49C    P8    17W / 250W |      9MiB / 22975MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1580    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      2016    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      2428    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      9568    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10840    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11424    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     22356    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     23080    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     23428    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     23684      C   ...z5n2kfra8p0\\python3.8.exe    N/A      |\n",
      "|    0   N/A  N/A     25640    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     26248      C   ...z5n2kfra8p0\\python3.8.exe    N/A      |\n",
      "|    0   N/A  N/A     27844    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     29344    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     29536    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ln' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "print('Git clone project and install requirements...')\n",
    "!git clone https://github.com/yzhou359/MakeItTalk #&> /dev/null\n",
    "%cd MakeItTalk/\n",
    "#!export PYTHONPATH=/content/MakeItTalk:$PYTHONPATH\n",
    "!pip install -r requirements.txt &> /dev/null\n",
    "!pip install tensorboardX &> /dev/null\n",
    "!mkdir examples/dump\n",
    "!mkdir examples/ckpt\n",
    "!pip install gdown &> /dev/null\n",
    "print('Done!')\n",
    "print('Download pre-trained models...') \n",
    "!gdown -O examples/ckpt/ckpt_autovc.pth https://drive.google.com/uc?id=1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x\n",
    "!gdown -O examples/ckpt/ckpt_content_branch.pth https://drive.google.com/uc?id=1r3bfEvTVl6pCNw5xwUhEglwDHjWtAqQp\n",
    "!gdown -O examples/ckpt/ckpt_speaker_branch.pth https://drive.google.com/uc?id=1rV0jkyDqPW-aDJcj7xSO6Zt1zSXqn1mu\n",
    "!gdown -O examples/ckpt/ckpt_116_i2i_comb.pth https://drive.google.com/uc?id=1i2LJXKp-yWKIEEgJ7C6cE3_2NirfY_0a\n",
    "!gdown -O examples/dump/emb.pickle https://drive.google.com/uc?id=18-0CYl5E6ungS3H4rRSHjfYvvm-WwjTI\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "import subprocess\n",
    "print(subprocess.getoutput('nvidia-smi'))\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "746ec2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement speech_recognition (from versions: none)\n",
      "ERROR: No matching distribution found for speech_recognition\n"
     ]
    }
   ],
   "source": [
    "!pip install speechrecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "junior-animal",
   "metadata": {
    "id": "aW4ktjHB89Du"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#!pip install git+https://github.com/huggingface/datasets.git\n",
    "#!pip install git+https://github.com/huggingface/transformers.git\n",
    "!pip install torchaudio\n",
    "!pip install librosa\n",
    "!pip install jiwer\n",
    "!pip install ffmpeg-python\n",
    "!pip install ipywidgets\n",
    "!pip install speechrecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59ccd273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\r2q2\\\\opt\\\\Saati_to_commit\\\\notebooks'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "collected-domestic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Speech Recognition thinks you said 123\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# obtain path to \"english.wav\" in the same folder as this script\n",
    "from os import path\n",
    "AUDIO_FILE = 'C:\\\\Users\\\\r2q2\\\\opt\\\\Saati_to_commit\\\\notebooks\\\\english.wav'#path.join(path.dirname(path.realpath('C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\english.wav')), \"english.wav\")\n",
    "\n",
    "# use the audio file as the audio source\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "    audio = r.record(source)  # read the entire audio file\n",
    "\n",
    "try:\n",
    "    # for testing purposes, we're just using the default API key\n",
    "    # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "    # instead of `r.recognize_google(audio)`\n",
    "    print(\"Google Speech Recognition thinks you said \" + r.recognize_google(audio))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "recognized = r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-security",
   "metadata": {
    "id": "YvnAhX7RTky-"
   },
   "source": [
    "Here we are performing speech recognition to get the utterance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "greater-experiment",
   "metadata": {
    "id": "vaSJEWDf4R03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Reusing dataset librispeech_asr (C:\\Users\\r2q2\\.cache\\huggingface\\datasets\\librispeech_asr\\clean\\2.1.0\\468ec03677f46a8714ac6b5b64dba02d246a228d92cbbad7f3dc190fa039eab1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1187d310679e49e09996e6837cd930e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=73.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function.Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(53.4790, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "input_values = processor(ds[\"speech\"][0], return_tensors=\"pt\").input_values  # Batch size 1\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "\n",
    "# compute loss\n",
    "target_transcription = \"A MAN SAID TO THE UNIVERSE SIR I EXIST\"\n",
    "\n",
    "# wrap processor as target processor to encode labels\n",
    "with processor.as_target_processor():\n",
    "    labels = processor(transcription, return_tensors=\"pt\").input_ids\n",
    "\n",
    "loss = model(input_values, labels=labels).loss\n",
    "transcription\n",
    "loss #TODO this needs to be looked in to or not used for this tech demo because it really isn't required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "existing-jacket",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
      "Reusing dataset librispeech_asr (C:\\Users\\r2q2\\.cache\\huggingface\\datasets\\librispeech_asr\\clean\\2.1.0\\468ec03677f46a8714ac6b5b64dba02d246a228d92cbbad7f3dc190fa039eab1)\n",
      "Loading cached processed dataset at C:\\Users\\r2q2\\.cache\\huggingface\\datasets\\librispeech_asr\\clean\\2.1.0\\468ec03677f46a8714ac6b5b64dba02d246a228d92cbbad7f3dc190fa039eab1\\cache-27f4be30f66ae10e.arrow\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function.Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"patrickvonplaten/wav2vec2-base-timit-demo\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"patrickvonplaten/wav2vec2-base-timit-demo\")\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "ds = ds.map(map_to_array)\n",
    "input_values = processor(ds[\"speech\"][0], return_tensors=\"pt\").input_values  # Batch size 1\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "# compute loss\n",
    "target_transcription = \"A MAN SAID TO THE UNIVERSE SIR I EXIST\"\n",
    "# wrap processor as target processor to encode labels\n",
    "with processor.as_target_processor():\n",
    "    labels = processor(transcription, return_tensors=\"pt\").input_ids\n",
    "loss = model(input_values, labels=labels).loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "horizontal-millennium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "first-chart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Egyptian cat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "former-allen",
   "metadata": {
    "id": "p6epEN6BbGn2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a64c5ee75174547a24f9d94efb4661a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2190.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6840ced5f8f449d9ca89bf6baa6d9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1700.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and preparing dataset librispeech_asr/clean (download: 28.05 GiB, generated: 54.01 MiB, post-processed: Unknown size, total: 28.11 GiB) to C:\\Users\\r2q2\\.cache\\huggingface\\datasets\\librispeech_asr\\clean\\2.1.0\\b534100631fdf6f7f1ac09901f6bd47ddc537fb506ec20b107a353de598c3bb0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3a7c168c60400db742a745bc1629d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f74d7f60bd4409a68dcdd7175ef17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-6445e6a850af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mlibrispeech_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"librispeech_asr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"clean\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWav2Vec2ForCTC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"facebook/wav2vec2-base-960h\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\datasets\\load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, script_version, use_auth_token, **config_kwargs)\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[1;31m# Download and prepare data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m     builder_instance.download_and_prepare(\n\u001b[0m\u001b[0;32m    747\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m         \u001b[0mdownload_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\datasets\\builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[1;34m(self, download_config, download_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m                             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"HF google storage unreachable. Downloading and preparing it from source\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdownloaded_from_gcs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m                         self._download_and_prepare(\n\u001b[0m\u001b[0;32m    588\u001b[0m                             \u001b[0mdl_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_infos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_infos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m                         )\n",
      "\u001b[1;32mc:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\datasets\\builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[1;34m(self, dl_manager, verify_infos, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m    663\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m                 \u001b[1;31m# Prepare split will record examples associated to the split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 665\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mprepare_split_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    666\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m                 raise OSError(\n",
      "\u001b[1;32mc:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\datasets\\builder.py\u001b[0m in \u001b[0;36m_prepare_split\u001b[1;34m(self, split_generator)\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mArrowWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter_batch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writer_batch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 992\u001b[1;33m                 for key, record in utils.tqdm(\n\u001b[0m\u001b[0;32m    993\u001b[0m                     \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\" examples\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplit_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnot_verbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m                 ):\n",
      "\u001b[1;32mc:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\librispeech_asr\\b534100631fdf6f7f1ac09901f6bd47ddc537fb506ec20b107a353de598c3bb0\\librispeech_asr.py\u001b[0m in \u001b[0;36m_generate_examples\u001b[1;34m(self, archive_path)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtranscript_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranscripts_glob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranscript_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranscript_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                     \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\codecs.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, errors)\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[0mbyte\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \"\"\"\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'strict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;31m# undecoded input that is kept between calls to decode()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from jiwer import wer\n",
    "\n",
    "\n",
    "librispeech_eval = load_dataset(\"librispeech_asr\", \"clean\", split=\"test\")\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\").to(\"cuda\")\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "librispeech_eval = librispeech_eval.map(map_to_array)\n",
    "\n",
    "def map_to_pred(batch):\n",
    "    input_values = tokenizer(batch[\"speech\"], return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values.to(\"cuda\")).logits\n",
    "\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = tokenizer.batch_decode(predicted_ids)\n",
    "    batch[\"transcription\"] = transcription\n",
    "    return batch\n",
    "\n",
    "result = librispeech_eval.map(map_to_pred, batched=True, batch_size=1, remove_columns=[\"speech\"])\n",
    "\n",
    "print(\"WER:\", wer(result[\"text\"], result[\"transcription\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-links",
   "metadata": {
    "id": "lbNQC_L2TwNW"
   },
   "source": [
    "Based on the recognised transcription we pass this into blenderbot-400-distill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "durable-aberdeen",
   "metadata": {
    "id": "eNi7NnsTYWIC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-ratio",
   "metadata": {
    "id": "Zb-UjOzD-zjT"
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import (\n",
    "    TFAutoModelWithLMHead,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    BlenderbotTokenizer,\n",
    "    BlenderbotSmallTokenizer,\n",
    "    BlenderbotForConditionalGeneration,\n",
    "    Conversation,\n",
    ")\n",
    "#from transformers import RobertaTokenizer, IBertModel\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import pipeline, Conversation\n",
    "#import logging\n",
    "from typing import List\n",
    "\n",
    "#conversational_pipeline = pipeline(\"conversational\", device=0)\n",
    "\n",
    "def blenderbot400M(utterance: str) -> List[str]:\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/blenderbot-400M-distill\")\n",
    "    inputs = tokenizer([utterance], return_tensors=\"pt\")\n",
    "    reply_ids = model.generate(**inputs)\n",
    "    responses = [\n",
    "        tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        for g in reply_ids\n",
    "    ]\n",
    "    return responses\n",
    "\n",
    "blenderbot400M(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-prerequisite",
   "metadata": {
    "id": "lJ0yNirUU6dV"
   },
   "outputs": [],
   "source": [
    "blenderbot400M(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-evans",
   "metadata": {
    "id": "93HLLOhSV5B8"
   },
   "source": [
    "Here we download mozillas TTS and use one of their models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "welsh-farming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-3.13.0.tar.gz (9.3 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from gdown) (3.0.12)\n",
      "Requirement already satisfied: tqdm in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from gdown) (4.49.0)\n",
      "Requirement already satisfied: requests[socks]>=2.12.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from gdown) (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from requests[socks]>=2.12.0->gdown) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from requests[socks]>=2.12.0->gdown) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from requests[socks]>=2.12.0->gdown) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from requests[socks]>=2.12.0->gdown) (2.10)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (PEP 517): started\n",
      "  Building wheel for gdown (PEP 517): finished with status 'done'\n",
      "  Created wheel for gdown: filename=gdown-3.13.0-py3-none-any.whl size=9034 sha256=6f53f4201c854aaaa7ccc063323080e5e9b7f51ed4a8e5cb7f5675792c99c74f\n",
      "  Stored in directory: c:\\users\\r2q2\\appdata\\local\\pip\\cache\\wheels\\04\\51\\53\\ed3e97af28b242e9eb81afb4836273fbe233a14228aa82fea3\n",
      "Successfully built gdown\n",
      "Installing collected packages: PySocks, gdown\n",
      "Successfully installed PySocks-1.7.1 gdown-3.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "civic-waters",
   "metadata": {
    "id": "xLFK2Re2cXeu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1dntzjWFg7ufWaTaFy80nRz-Tu02xWZos\n",
      "To: C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\tts_model.pth.tar\n",
      "\n",
      "0.00B [00:00, ?B/s]\n",
      "1.05MB [00:00, 9.59MB/s]\n",
      "5.77MB [00:00, 12.5MB/s]\n",
      "8.91MB [00:00, 13.3MB/s]\n",
      "16.8MB [00:00, 17.5MB/s]\n",
      "19.9MB [00:00, 17.4MB/s]\n",
      "25.7MB [00:00, 20.2MB/s]\n",
      "33.0MB [00:01, 25.4MB/s]\n",
      "37.2MB [00:01, 25.5MB/s]\n",
      "42.5MB [00:01, 25.9MB/s]\n",
      "50.3MB [00:01, 32.1MB/s]\n",
      "55.1MB [00:01, 29.6MB/s]\n",
      "59.2MB [00:01, 31.1MB/s]\n",
      "67.6MB [00:01, 33.8MB/s]\n",
      "74.4MB [00:02, 39.8MB/s]\n",
      "79.7MB [00:02, 38.1MB/s]\n",
      "84.4MB [00:02, 35.4MB/s]\n",
      "92.3MB [00:02, 41.7MB/s]\n",
      "101MB [00:02, 48.1MB/s] \n",
      "109MB [00:02, 53.4MB/s]\n",
      "118MB [00:02, 58.9MB/s]\n",
      "126MB [00:02, 62.5MB/s]\n",
      "135MB [00:03, 66.3MB/s]\n",
      "143MB [00:03, 69.2MB/s]\n",
      "151MB [00:03, 71.9MB/s]\n",
      "159MB [00:03, 73.8MB/s]\n",
      "167MB [00:03, 74.8MB/s]\n",
      "176MB [00:03, 76.0MB/s]\n",
      "185MB [00:03, 78.2MB/s]\n",
      "194MB [00:03, 78.5MB/s]\n",
      "203MB [00:03, 80.2MB/s]\n",
      "212MB [00:04, 80.2MB/s]\n",
      "221MB [00:04, 75.9MB/s]\n",
      "229MB [00:04, 77.4MB/s]\n",
      "237MB [00:04, 77.3MB/s]\n",
      "245MB [00:04, 77.5MB/s]\n",
      "253MB [00:04, 75.9MB/s]\n",
      "262MB [00:04, 77.4MB/s]\n",
      "270MB [00:04, 76.9MB/s]\n",
      "279MB [00:04, 77.7MB/s]\n",
      "287MB [00:05, 72.4MB/s]\n",
      "294MB [00:05, 71.2MB/s]\n",
      "301MB [00:05, 51.7MB/s]\n",
      "308MB [00:05, 54.6MB/s]\n",
      "317MB [00:05, 59.8MB/s]\n",
      "325MB [00:05, 63.0MB/s]\n",
      "333MB [00:05, 67.5MB/s]\n",
      "342MB [00:05, 70.7MB/s]\n",
      "347MB [00:05, 58.1MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=18CQ6G6tBEOfvCHlPqP8EBI4xWbrr9dBc\n",
      "To: C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\config.json\n",
      "\n",
      "  0%|          | 0.00/9.53k [00:00<?, ?B/s]\n",
      "100%|##########| 9.53k/9.53k [00:00<?, ?B/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Ty5DZdOc0F7OTGj9oJThYbL5iVu_2G0K\n",
      "To: C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\vocoder_model.pth.tar\n",
      "\n",
      "0.00B [00:00, ?B/s]\n",
      "1.57MB [00:00, 14.0MB/s]\n",
      "4.72MB [00:00, 16.2MB/s]\n",
      "8.91MB [00:00, 16.4MB/s]\n",
      "17.3MB [00:00, 19.2MB/s]\n",
      "25.7MB [00:00, 22.3MB/s]\n",
      "34.1MB [00:01, 24.6MB/s]\n",
      "42.5MB [00:01, 27.3MB/s]\n",
      "50.3MB [00:01, 33.5MB/s]\n",
      "55.1MB [00:01, 31.4MB/s]\n",
      "59.2MB [00:01, 28.3MB/s]\n",
      "67.6MB [00:02, 30.0MB/s]\n",
      "76.0MB [00:02, 32.2MB/s]\n",
      "82.8MB [00:02, 33.6MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Rd0R_nRCrbjEdpOwq6XwZAktvugiBvmu\n",
      "To: C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\config_vocoder.json\n",
      "\n",
      "  0%|          | 0.00/6.76k [00:00<?, ?B/s]\n",
      "100%|##########| 6.76k/6.76k [00:00<?, ?B/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=11oY3Tv0kQtxK_JPgxrfesa99maVXHNxU\n",
      "To: C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\scale_stats.npy\n",
      "\n",
      "  0%|          | 0.00/10.5k [00:00<?, ?B/s]\n",
      "100%|##########| 10.5k/10.5k [00:00<?, ?B/s]\n",
      "Cloning into 'TTS'...\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1dntzjWFg7ufWaTaFy80nRz-Tu02xWZos -O tts_model.pth.tar\n",
    "!gdown --id 18CQ6G6tBEOfvCHlPqP8EBI4xWbrr9dBc -O config.json\n",
    "!gdown --id 1Ty5DZdOc0F7OTGj9oJThYbL5iVu_2G0K -O vocoder_model.pth.tar\n",
    "!gdown --id 1Rd0R_nRCrbjEdpOwq6XwZAktvugiBvmu -O config_vocoder.json\n",
    "!gdown --id 11oY3Tv0kQtxK_JPgxrfesa99maVXHNxU -O scale_stats.npy\n",
    "\n",
    "#! sudo apt-get install espeak\n",
    "!git clone https://github.com/coqui-ai/TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5dc33f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inflect\n",
      "  Downloading inflect-5.3.0-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: inflect\n",
      "Successfully installed inflect-5.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "excessive-accuracy",
   "metadata": {
    "id": "Mr5AvZq3EI8o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooks\\TTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HEAD is now at b1935c9 update server to enable native vocoder inference and remove pwgan support\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from -r requirements.txt (line 1)) (1.20.2)\n",
      "Requirement already satisfied: torch>=1.5 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.9.0.dev20210425+cu111)\n",
      "Requirement already satisfied: librosa>=0.5.1 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from -r requirements.txt (line 3)) (0.8.0)\n",
      "Requirement already satisfied: Unidecode>=0.4.20 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from -r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from -r requirements.txt (line 5)) (2.5.0)\n",
      "Requirement already satisfied: tensorboardX in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from -r requirements.txt (line 6)) (2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from -r requirements.txt (line 7)) (3.4.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from -r requirements.txt (line 8)) (8.1.1)\n",
      "Requirement already satisfied: flask in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from -r requirements.txt (line 9)) (1.1.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from -r requirements.txt (line 10)) (1.6.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from -r requirements.txt (line 11)) (4.49.0)\n",
      "Requirement already satisfied: soundfile in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from -r requirements.txt (line 12)) (0.10.3.post1)\n",
      "Requirement already satisfied: phonemizer in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from -r requirements.txt (line 13)) (2.2.2)\n",
      "Requirement already satisfied: bokeh==1.4.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from -r requirements.txt (line 14)) (1.4.0)\n",
      "Requirement already satisfied: tornado>=4.3 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from bokeh==1.4.0->-r requirements.txt (line 14)) (6.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from bokeh==1.4.0->-r requirements.txt (line 14)) (2.11.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from bokeh==1.4.0->-r requirements.txt (line 14)) (2.8.1)\n",
      "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from bokeh==1.4.0->-r requirements.txt (line 14)) (5.4.1)\n",
      "Requirement already satisfied: packaging>=16.8 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from bokeh==1.4.0->-r requirements.txt (line 14)) (20.9)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from bokeh==1.4.0->-r requirements.txt (line 14)) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from torch>=1.5->-r requirements.txt (line 2)) (3.7.4.3)\n",
      "Requirement already satisfied: audioread>=2.0.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from librosa>=0.5.1->-r requirements.txt (line 3)) (2.1.9)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from librosa>=0.5.1->-r requirements.txt (line 3)) (0.24.1)\n",
      "Requirement already satisfied: numba>=0.43.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from librosa>=0.5.1->-r requirements.txt (line 3)) (0.53.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from librosa>=0.5.1->-r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from librosa>=0.5.1->-r requirements.txt (line 3)) (0.2.2)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from librosa>=0.5.1->-r requirements.txt (line 3)) (5.0.7)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from librosa>=0.5.1->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from soundfile->-r requirements.txt (line 12)) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 12)) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from Jinja2>=2.7->bokeh==1.4.0->-r requirements.txt (line 14)) (1.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from numba>=0.43.0->librosa>=0.5.1->-r requirements.txt (line 3)) (49.2.1)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from numba>=0.43.0->librosa>=0.5.1->-r requirements.txt (line 3)) (0.36.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from packaging>=16.8->bokeh==1.4.0->-r requirements.txt (line 14)) (2.4.7)\n",
      "Requirement already satisfied: appdirs in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from pooch>=1.0->librosa>=0.5.1->-r requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: requests in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from pooch>=1.0->librosa>=0.5.1->-r requirements.txt (line 3)) (2.25.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.5.1->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 5)) (0.4.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 5)) (1.37.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 5)) (1.30.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 5)) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 5)) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 5)) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 5)) (3.16.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 5)) (0.36.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from requests->pooch>=1.0->librosa>=0.5.1->-r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from requests->pooch>=1.0->librosa>=0.5.1->-r requirements.txt (line 3)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from requests->pooch>=1.0->librosa>=0.5.1->-r requirements.txt (line 3)) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from requests->pooch>=1.0->librosa>=0.5.1->-r requirements.txt (line 3)) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 5)) (3.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 7)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from flask->-r requirements.txt (line 9)) (7.1.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from flask->-r requirements.txt (line 9)) (1.1.0)\n",
      "Requirement already satisfied: segments in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from phonemizer->-r requirements.txt (line 13)) (2.2.0)\n",
      "Requirement already satisfied: attrs>=18.1 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from phonemizer->-r requirements.txt (line 13)) (20.3.0)\n",
      "Requirement already satisfied: regex in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from segments->phonemizer->-r requirements.txt (line 13)) (2021.4.4)\n",
      "Requirement already satisfied: clldutils>=1.7.3 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from segments->phonemizer->-r requirements.txt (line 13)) (3.8.0)\n",
      "Requirement already satisfied: csvw>=1.5.6 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from segments->phonemizer->-r requirements.txt (line 13)) (1.11.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from clldutils>=1.7.3->segments->phonemizer->-r requirements.txt (line 13)) (0.8.9)\n",
      "Requirement already satisfied: colorlog in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from clldutils>=1.7.3->segments->phonemizer->-r requirements.txt (line 13)) (5.0.1)\n",
      "Requirement already satisfied: rfc3986 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 13)) (1.5.0)\n",
      "Requirement already satisfied: uritemplate>=3.0.0 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 13)) (3.0.1)\n",
      "Requirement already satisfied: isodate in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 13)) (0.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from colorlog->clldutils>=1.7.3->segments->phonemizer->-r requirements.txt (line 13)) (0.4.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing tts_namespace\\TTS.egg-info\\PKG-INFO\n",
      "writing dependency_links to tts_namespace\\TTS.egg-info\\dependency_links.txt\n",
      "writing entry points to tts_namespace\\TTS.egg-info\\entry_points.txt\n",
      "writing requirements to tts_namespace\\TTS.egg-info\\requires.txt\n",
      "writing top-level names to tts_namespace\\TTS.egg-info\\top_level.txt\n",
      "reading manifest file 'tts_namespace\\TTS.egg-info\\SOURCES.txt'\n",
      "writing manifest file 'tts_namespace\\TTS.egg-info\\SOURCES.txt'\n",
      "installing library code to build\\bdist.win-amd64\\egg\n",
      "running install_lib\n",
      "creating build\\bdist.win-amd64\\egg\n",
      "creating build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying tts_namespace\\TTS.egg-info\\PKG-INFO -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying tts_namespace\\TTS.egg-info\\SOURCES.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying tts_namespace\\TTS.egg-info\\dependency_links.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying tts_namespace\\TTS.egg-info\\entry_points.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying tts_namespace\\TTS.egg-info\\requires.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying tts_namespace\\TTS.egg-info\\top_level.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "creating 'dist\\TTS-0.0.3+b1935c9-py3.8.egg' and adding 'build\\bdist.win-amd64\\egg' to it\n",
      "removing 'build\\bdist.win-amd64\\egg' (and everything under it)\n",
      "Processing TTS-0.0.3+b1935c9-py3.8.egg\n",
      "Removing c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\TTS-0.0.3+b1935c9-py3.8.egg\n",
      "Copying TTS-0.0.3+b1935c9-py3.8.egg to c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "TTS 0.0.3+b1935c9 is already the active version in easy-install.pth\n",
      "Installing tts-server-script.py script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "Installing tts-server.exe script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "\n",
      "Installed c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\tts-0.0.3+b1935c9-py3.8.egg\n",
      "Processing dependencies for TTS==0.0.3+b1935c9\n",
      "Searching for phonemizer==2.2.2\n",
      "Best match: phonemizer 2.2.2\n",
      "Adding phonemizer 2.2.2 to easy-install.pth file\n",
      "Installing phonemize-script.py script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "Installing phonemize.exe script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for SoundFile==0.10.3.post1\n",
      "Best match: SoundFile 0.10.3.post1\n",
      "Adding SoundFile 0.10.3.post1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for bokeh==1.4.0\n",
      "Best match: bokeh 1.4.0\n",
      "Adding bokeh 1.4.0 to easy-install.pth file\n",
      "Installing bokeh-script.py script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "Installing bokeh.exe script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for tqdm==4.49.0\n",
      "Best match: tqdm 4.49.0\n",
      "Adding tqdm 4.49.0 to easy-install.pth file\n",
      "Installing tqdm-script.py script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "Installing tqdm.exe script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for Flask==1.1.2\n",
      "Best match: Flask 1.1.2\n",
      "Adding Flask 1.1.2 to easy-install.pth file\n",
      "Installing flask-script.py script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "Installing flask.exe script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for Pillow==8.1.1\n",
      "Best match: Pillow 8.1.1\n",
      "Adding Pillow 8.1.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for matplotlib==3.4.2\n",
      "Best match: matplotlib 3.4.2\n",
      "Adding matplotlib 3.4.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for tensorboardX==2.2\n",
      "Best match: tensorboardX 2.2\n",
      "Adding tensorboardX 2.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for attrdict==2.0.1\n",
      "Best match: attrdict 2.0.1\n",
      "Processing attrdict-2.0.1-py3.8.egg\n",
      "attrdict 2.0.1 is already the active version in easy-install.pth\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\attrdict-2.0.1-py3.8.egg\n",
      "Searching for unidecode==0.4.20\n",
      "Best match: unidecode 0.4.20\n",
      "Processing unidecode-0.4.20-py3.8.egg\n",
      "unidecode 0.4.20 is already the active version in easy-install.pth\n",
      "Installing unidecode-script.py script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "Installing unidecode.exe script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\unidecode-0.4.20-py3.8.egg\n",
      "Searching for librosa==0.6.2\n",
      "Best match: librosa 0.6.2\n",
      "Processing librosa-0.6.2-py3.8.egg\n",
      "librosa 0.6.2 is already the active version in easy-install.pth\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\\librosa-0.6.2-py3.8.egg\n",
      "C:\\Users\\r2q2\\opt\\Saati_to_commit\\notebooksSearching for numpy==1.20.2\n",
      "\n",
      "Best match: numpy 1.20.2\n",
      "Adding numpy 1.20.2 to easy-install.pth file\n",
      "Installing f2py-script.py script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "Installing f2py.exe script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for torch==1.9.0.dev20210425+cu111\n",
      "Best match: torch 1.9.0.dev20210425+cu111\n",
      "Adding torch 1.9.0.dev20210425+cu111 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx-script.py script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "Installing convert-caffe2-to-onnx.exe script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "Installing convert-onnx-to-caffe2-script.py script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "Installing convert-onnx-to-caffe2.exe script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for scipy==1.6.2\n",
      "Best match: scipy 1.6.2\n",
      "Adding scipy 1.6.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for attrs==20.3.0\n",
      "Best match: attrs 20.3.0\n",
      "Adding attrs 20.3.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for joblib==1.0.1\n",
      "Best match: joblib 1.0.1\n",
      "Adding joblib 1.0.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for segments==2.2.0\n",
      "Best match: segments 2.2.0\n",
      "Adding segments 2.2.0 to easy-install.pth file\n",
      "Installing segments-script.py script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "Installing segments.exe script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for cffi==1.14.5\n",
      "Best match: cffi 1.14.5\n",
      "Adding cffi 1.14.5 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: install_lib: 'temp_build' does not exist -- no Python modules to install\n",
      "\n",
      "zip_safe flag not set; analyzing archive contents...\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x8f in position 3058: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-91fc0607e656>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mVOCODER_CONFIG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"config_vocoder.json\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# load configs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mTTS_CONFIG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTTS_CONFIG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mVOCODER_CONFIG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVOCODER_CONFIG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# load the audio processor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\opt\\Saati_to_commit\\notebooks\\TTS\\utils\\io.py\u001b[0m in \u001b[0;36mload_config\u001b[1;34m(config_path)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAttrDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0minput_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0minput_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\\\\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0minput_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'//.*\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8f in position 3058: character maps to <undefined>"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for packaging==20.9\n",
      "Best match: packaging 20.9\n",
      "Adding packaging 20.9 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for tornado==6.1\n",
      "Best match: tornado 6.1\n",
      "Adding tornado 6.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for six==1.15.0\n",
      "Best match: six 1.15.0\n",
      "Adding six 1.15.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for Jinja2==2.11.3\n",
      "Best match: Jinja2 2.11.3\n",
      "Adding Jinja2 2.11.3 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for python-dateutil==2.8.1\n",
      "Best match: python-dateutil 2.8.1\n",
      "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for PyYAML==5.4.1\n",
      "Best match: PyYAML 5.4.1\n",
      "Adding PyYAML 5.4.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for itsdangerous==1.1.0\n",
      "Best match: itsdangerous 1.1.0\n",
      "Adding itsdangerous 1.1.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for click==7.1.2\n",
      "Best match: click 7.1.2\n",
      "Adding click 7.1.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for Werkzeug==1.0.1\n",
      "Best match: Werkzeug 1.0.1\n",
      "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for cycler==0.10.0\n",
      "Best match: cycler 0.10.0\n",
      "Adding cycler 0.10.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for pyparsing==2.4.7\n",
      "Best match: pyparsing 2.4.7\n",
      "Adding pyparsing 2.4.7 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for kiwisolver==1.3.1\n",
      "Best match: kiwisolver 1.3.1\n",
      "Adding kiwisolver 1.3.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for protobuf==3.16.0\n",
      "Best match: protobuf 3.16.0\n",
      "Adding protobuf 3.16.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for numba==0.53.1\n",
      "Best match: numba 0.53.1\n",
      "Adding numba 0.53.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for resampy==0.2.2\n",
      "Best match: resampy 0.2.2\n",
      "Adding resampy 0.2.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for decorator==5.0.7\n",
      "Best match: decorator 5.0.7\n",
      "Adding decorator 5.0.7 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for scikit-learn==0.24.1\n",
      "Best match: scikit-learn 0.24.1\n",
      "Adding scikit-learn 0.24.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for audioread==2.1.9\n",
      "Best match: audioread 2.1.9\n",
      "Adding audioread 2.1.9 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for typing-extensions==3.7.4.3\n",
      "Best match: typing-extensions 3.7.4.3\n",
      "Adding typing-extensions 3.7.4.3 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for clldutils==3.8.0\n",
      "Best match: clldutils 3.8.0\n",
      "Adding clldutils 3.8.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for csvw==1.11.0\n",
      "Best match: csvw 1.11.0\n",
      "Adding csvw 1.11.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for regex==2021.4.4\n",
      "Best match: regex 2021.4.4\n",
      "Adding regex 2021.4.4 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for pycparser==2.20\n",
      "Best match: pycparser 2.20\n",
      "Adding pycparser 2.20 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for MarkupSafe==1.1.1\n",
      "Best match: MarkupSafe 1.1.1\n",
      "Adding MarkupSafe 1.1.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for setuptools==49.2.1\n",
      "Best match: setuptools 49.2.1\n",
      "Adding setuptools 49.2.1 to easy-install.pth file\n",
      "Installing easy_install-script.py script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "Installing easy_install.exe script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "Installing easy_install-3.8-script.py script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "Installing easy_install-3.8.exe script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for llvmlite==0.36.0\n",
      "Best match: llvmlite 0.36.0\n",
      "Adding llvmlite 0.36.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for threadpoolctl==2.1.0\n",
      "Best match: threadpoolctl 2.1.0\n",
      "Adding threadpoolctl 2.1.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for tabulate==0.8.9\n",
      "Best match: tabulate 0.8.9\n",
      "Adding tabulate 0.8.9 to easy-install.pth file\n",
      "Installing tabulate-script.py script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "Installing tabulate.exe script to C:\\Users\\r2q2\\opt\\Saati_to_commit\\venv\\Scripts\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for colorlog==5.0.1\n",
      "Best match: colorlog 5.0.1\n",
      "Adding colorlog 5.0.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for uritemplate==3.0.1\n",
      "Best match: uritemplate 3.0.1\n",
      "Adding uritemplate 3.0.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for rfc3986==1.5.0\n",
      "Best match: rfc3986 1.5.0\n",
      "Adding rfc3986 1.5.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for isodate==0.6.0\n",
      "Best match: isodate 0.6.0\n",
      "Adding isodate 0.6.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Searching for colorama==0.4.4\n",
      "Best match: colorama 0.4.4\n",
      "Adding colorama 0.4.4 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages\n",
      "Finished processing dependencies for TTS==0.0.3+b1935c9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%cd TTS\n",
    "!git checkout b1935c97\n",
    "!pip install -r requirements.txt\n",
    "!python setup.py install\n",
    "%cd ..\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "744fbbf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x8f in position 3058: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-60bb89b31c16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mVOCODER_CONFIG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:\\\\Users\\\\r2q2\\opt\\\\Saati_to_commit\\\\models\\\\config_vocoder.json\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# load configs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mTTS_CONFIG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTTS_CONFIG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mVOCODER_CONFIG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVOCODER_CONFIG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# load the audio processor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\opt\\Saati_to_commit\\notebooks\\TTS\\utils\\io.py\u001b[0m in \u001b[0;36mload_config\u001b[1;34m(config_path)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAttrDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0minput_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0minput_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\\\\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0minput_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'//.*\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8f in position 3058: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import IPython\n",
    "\n",
    "from TTS.utils.generic_utils import setup_model\n",
    "from TTS.utils.io import load_config\n",
    "from TTS.utils.text.symbols import symbols, phonemes\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from TTS.utils.synthesis import synthesis\n",
    "from TTS.vocoder.utils.generic_utils import setup_generator\n",
    "\n",
    "# runtime settings\n",
    "use_cuda = False\n",
    "# model paths\n",
    "TTS_MODEL = \"C:\\\\Users\\\\r2q2\\\\opt\\\\Saati_to_commit\\\\models\\\\tts_model.pth.tar\"\n",
    "TTS_CONFIG = \"C:\\\\Users\\\\r2q2\\\\opt\\\\Saati_to_commit\\\\models\\\\config.json\"\n",
    "VOCODER_MODEL = \"C:\\\\Users\\\\r2q2\\\\opt\\\\Saati_to_commit\\\\models\\\\vocoder_model.pth.tar\"\n",
    "VOCODER_CONFIG = \"C:\\\\Users\\\\r2q2\\opt\\\\Saati_to_commit\\\\models\\\\config_vocoder.json\"\n",
    "# load configs\n",
    "TTS_CONFIG = load_config(TTS_CONFIG)\n",
    "VOCODER_CONFIG = load_config(VOCODER_CONFIG)\n",
    "# load the audio processor\n",
    "ap = AudioProcessor(**TTS_CONFIG.audio)\n",
    "# LOAD TTS MODEL\n",
    "# multi speaker \n",
    "speaker_id = None\n",
    "speakers = []\n",
    "\n",
    "# load the model\n",
    "num_chars = len(phonemes) if TTS_CONFIG.use_phonemes else len(symbols)\n",
    "model = setup_model(num_chars, len(speakers), TTS_CONFIG)\n",
    "\n",
    "# load model state\n",
    "cp =  torch.load(TTS_MODEL, map_location=torch.device('cpu'))\n",
    "\n",
    "# load the model\n",
    "model.load_state_dict(cp['model'])\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "model.eval()\n",
    "\n",
    "# set model stepsize\n",
    "if 'r' in cp:\n",
    "    model.decoder.set_r(cp['r'])\n",
    "\n",
    "# LOAD VOCODER MODEL\n",
    "vocoder_model = setup_generator(VOCODER_CONFIG)\n",
    "vocoder_model.load_state_dict(torch.load(VOCODER_MODEL, map_location=\"cpu\")[\"model\"])\n",
    "vocoder_model.remove_weight_norm()\n",
    "vocoder_model.inference_padding = 0\n",
    "\n",
    "ap_vocoder = AudioProcessor(**VOCODER_CONFIG['audio'])    \n",
    "if use_cuda:\n",
    "    vocoder_model.cuda()\n",
    "vocoder_model.eval()\n",
    "\n",
    "def tts(model, text, CONFIG, use_cuda, ap, use_gl, figures=True):\n",
    "    t_1 = time.time()\n",
    "    waveform, alignment, mel_spec, mel_postnet_spec, stop_tokens, inputs = synthesis(model, text, CONFIG, use_cuda, ap, speaker_id, style_wav=None,\n",
    "                                                                             truncated=False, enable_eos_bos_chars=CONFIG.enable_eos_bos_chars)\n",
    "    # mel_postnet_spec = ap._denormalize(mel_postnet_spec.T)\n",
    "    if not use_gl:\n",
    "        waveform = vocoder_model.inference(torch.FloatTensor(mel_postnet_spec.T).unsqueeze(0))\n",
    "        waveform = waveform.flatten()\n",
    "    if use_cuda:\n",
    "        waveform = waveform.cpu()\n",
    "    waveform = waveform.numpy()\n",
    "    rtf = (time.time() - t_1) / (len(waveform) / ap.sample_rate)\n",
    "    tps = (time.time() - t_1) / len(waveform)\n",
    "    print(waveform.shape)\n",
    "    print(\" > Run-time: {}\".format(time.time() - t_1))\n",
    "    print(\" > Real-time factor: {}\".format(rtf))\n",
    "    print(\" > Time per step: {}\".format(tps))\n",
    "    IPython.display.display(IPython.display.Audio(waveform, rate=CONFIG.audio['sample_rate']))  \n",
    "    return alignment, mel_postnet_spec, stop_tokens, waveform\n",
    "\n",
    "sentence =  \"Bill got in the habit of asking himself.\"\n",
    "#align, spec, stop_tokens, wav = tts(model, sentence, TTS_CONFIG, use_cuda, ap, use_gl=False, figures=True)\n",
    "align, spec, stop_tokens, wav = tts(model, blenderbot400M(transcription)[0], TTS_CONFIG, use_cuda, ap, use_gl=False, figures=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "casual-spirit",
   "metadata": {
    "id": "zs_dYZWzc2d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (1.6.2)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\users\\r2q2\\opt\\saati_to_commit\\venv\\lib\\site-packages (from scipy) (1.20.2)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'wav' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-f976dc8e66d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwavfile\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msamplerate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m22050\u001b[0m\u001b[1;33m;\u001b[0m \u001b[1;31m#fs = 100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../test.wav'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'wav' is not defined"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "from scipy.io.wavfile import write\n",
    "samplerate = 22050; #fs = 100\n",
    "write('../test.wav', samplerate, wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-wedding",
   "metadata": {
    "id": "4lNScvXmex0g"
   },
   "outputs": [],
   "source": [
    "print('Git clone project and install requirements...')\n",
    "!git clone https://github.com/yzhou359/MakeItTalk &> /dev/null\n",
    "%cd MakeItTalk/\n",
    "!export PYTHONPATH=/content/MakeItTalk:$PYTHONPATH\n",
    "!pip install -r requirements.txt &> /dev/null\n",
    "!pip install tensorboardX &> /dev/null\n",
    "!mkdir examples/dump\n",
    "!mkdir examples/ckpt\n",
    "!pip install gdown &> /dev/null\n",
    "print('Done!')\n",
    "print('Download pre-trained models...')\n",
    "!gdown -O examples/ckpt/ckpt_autovc.pth https://drive.google.com/uc?id=1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x\n",
    "!gdown -O examples/ckpt/ckpt_content_branch.pth https://drive.google.com/uc?id=1r3bfEvTVl6pCNw5xwUhEglwDHjWtAqQp\n",
    "!gdown -O examples/ckpt/ckpt_speaker_branch.pth https://drive.google.com/uc?id=1rV0jkyDqPW-aDJcj7xSO6Zt1zSXqn1mu\n",
    "!gdown -O examples/ckpt/ckpt_116_i2i_comb.pth https://drive.google.com/uc?id=1i2LJXKp-yWKIEEgJ7C6cE3_2NirfY_0a\n",
    "!gdown -O examples/dump/emb.pickle https://drive.google.com/uc?id=18-0CYl5E6ungS3H4rRSHjfYvvm-WwjTI\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-excerpt",
   "metadata": {
    "id": "iRZ-NZypOuIN"
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"Choose the image name to animate: (saved in folder 'examples/')\")\n",
    "img_list = glob.glob1('examples', '*.jpg')\n",
    "img_list.sort()\n",
    "img_list = [item.split('.')[0] for item in img_list]\n",
    "default_head_name = widgets.Dropdown(options=img_list, value='paint_boy')\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        plt.imshow(plt.imread('examples/{}.jpg'.format(default_head_name.value)))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "default_head_name.observe(on_change)\n",
    "display(default_head_name)\n",
    "plt.imshow(plt.imread('examples/{}.jpg'.format(default_head_name.value)))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-smell",
   "metadata": {
    "id": "mkH0WKbDhO5t"
   },
   "outputs": [],
   "source": [
    "\n",
    "#@markdown # Animation Controllers\n",
    "#@markdown Amplify the lip motion in horizontal direction\n",
    "AMP_LIP_SHAPE_X = 2.8 #@param {type:\"slider\", min:0.5, max:5.0, step:0.1}\n",
    "\n",
    "#@markdown Amplify the lip motion in vertical direction\n",
    "AMP_LIP_SHAPE_Y = 2 #@param {type:\"slider\", min:0.5, max:5.0, step:0.1}\n",
    "\n",
    "#@markdown Amplify the head pose motion (usually smaller than 1.0, put it to 0. for a static head pose)\n",
    "AMP_HEAD_POSE_MOTION = 0.35 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
    "\n",
    "#@markdown Add naive eye blink\n",
    "ADD_NAIVE_EYE = True  #@param [\"False\", \"True\"] {type:\"raw\"}\n",
    "\n",
    "#@markdown If your image has an opened mouth, put this as True, else False\n",
    "CLOSE_INPUT_FACE_MOUTH = False  #@param [\"False\", \"True\"] {type:\"raw\"}          \n",
    "\n",
    "\n",
    "#@markdown # Landmark Adjustment\n",
    "\n",
    "#@markdown Adjust upper lip thickness (postive value means thicker)\n",
    "UPPER_LIP_ADJUST = -1 #@param {type:\"slider\", min:-3.0, max:3.0, step:1.0}\n",
    "\n",
    "#@markdown Adjust lower lip thickness (postive value means thicker)\n",
    "LOWER_LIP_ADJUST = -1 #@param {type:\"slider\", min:-3.0, max:3.0, step:1.0}\n",
    "\n",
    "#@markdown Adjust static lip width (in multipication)\n",
    "LIP_WIDTH_ADJUST = 1.0 #@param {type:\"slider\", min:0.8, max:1.2, step:0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-abortion",
   "metadata": {
    "id": "BFajpH1aOyjs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-invalid",
   "metadata": {
    "id": "vAfQWE6jO1IF"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"thirdparty/AdaptiveWingLoss\")\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "from src.approaches.train_image_translation import Image_translation_block\n",
    "import torch\n",
    "import pickle\n",
    "import face_alignment\n",
    "from src.autovc.AutoVC_mel_Convertor_retrain_version import AutoVC_mel_Convertor\n",
    "import shutil\n",
    "import time\n",
    "import util.utils as util\n",
    "from scipy.signal import savgol_filter\n",
    "from src.approaches.train_audio2landmark import Audio2landmark_model\n",
    "\n",
    "sys.stdout = open(os.devnull, 'a')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--jpg', type=str, default='{}.jpg'.format(default_head_name.value))\n",
    "parser.add_argument('--close_input_face_mouth', default=CLOSE_INPUT_FACE_MOUTH, action='store_true')\n",
    "parser.add_argument('--load_AUTOVC_name', type=str, default='examples/ckpt/ckpt_autovc.pth')\n",
    "parser.add_argument('--load_a2l_G_name', type=str, default='examples/ckpt/ckpt_speaker_branch.pth')\n",
    "parser.add_argument('--load_a2l_C_name', type=str, default='examples/ckpt/ckpt_content_branch.pth') #ckpt_audio2landmark_c.pth')\n",
    "parser.add_argument('--load_G_name', type=str, default='examples/ckpt/ckpt_116_i2i_comb.pth') #ckpt_image2image.pth') #ckpt_i2i_finetune_150.pth') #c\n",
    "parser.add_argument('--amp_lip_x', type=float, default=AMP_LIP_SHAPE_X)\n",
    "parser.add_argument('--amp_lip_y', type=float, default=AMP_LIP_SHAPE_Y)\n",
    "parser.add_argument('--amp_pos', type=float, default=AMP_HEAD_POSE_MOTION)\n",
    "parser.add_argument('--reuse_train_emb_list', type=str, nargs='+', default=[]) #  ['iWeklsXc0H8']) #['45hn7-LXDX8']) #['E_kmpT-EfOg']) #'iWeklsXc0H8', '29k8RtSUjE0', '45hn7-LXDX8',\n",
    "parser.add_argument('--add_audio_in', default=False, action='store_true')\n",
    "parser.add_argument('--comb_fan_awing', default=False, action='store_true')\n",
    "parser.add_argument('--output_folder', type=str, default='examples')\n",
    "parser.add_argument('--test_end2end', default=True, action='store_true')\n",
    "parser.add_argument('--dump_dir', type=str, default='', help='')\n",
    "parser.add_argument('--pos_dim', default=7, type=int)\n",
    "parser.add_argument('--use_prior_net', default=True, action='store_true')\n",
    "parser.add_argument('--transformer_d_model', default=32, type=int)\n",
    "parser.add_argument('--transformer_N', default=2, type=int)\n",
    "parser.add_argument('--transformer_heads', default=2, type=int)\n",
    "parser.add_argument('--spk_emb_enc_size', default=16, type=int)\n",
    "parser.add_argument('--init_content_encoder', type=str, default='')\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help='learning rate')\n",
    "parser.add_argument('--reg_lr', type=float, default=1e-6, help='weight decay')\n",
    "parser.add_argument('--write', default=False, action='store_true')\n",
    "parser.add_argument('--segment_batch_size', type=int, default=1, help='batch size')\n",
    "parser.add_argument('--emb_coef', default=3.0, type=float)\n",
    "parser.add_argument('--lambda_laplacian_smooth_loss', default=1.0, type=float)\n",
    "parser.add_argument('--use_11spk_only', default=False, action='store_true')\n",
    "parser.add_argument('-f')\n",
    "opt_parser = parser.parse_args()\n",
    "\n",
    "img = cv2.imread('examples/' + opt_parser.jpg)\n",
    "predictor = face_alignment.FaceAlignment(face_alignment.LandmarksType._3D, device='cpu', flip_input=True)\n",
    "shapes = predictor.get_landmarks(img)\n",
    "if (not shapes or len(shapes) != 1):\n",
    "    print('Cannot detect face landmarks. Exit.')\n",
    "    exit(-1)\n",
    "shape_3d = shapes[0]\n",
    "if(opt_parser.close_input_face_mouth):\n",
    "    util.close_input_face_mouth(shape_3d)\n",
    "shape_3d[48:, 0] = (shape_3d[48:, 0] - np.mean(shape_3d[48:, 0])) * LIP_WIDTH_ADJUST + np.mean(shape_3d[48:, 0]) # wider lips\n",
    "shape_3d[49:54, 1] -= UPPER_LIP_ADJUST           # thinner upper lip\n",
    "shape_3d[55:60, 1] += LOWER_LIP_ADJUST           # thinner lower lip\n",
    "shape_3d[[37,38,43,44], 1] -=2.    # larger eyes\n",
    "shape_3d[[40,41,46,47], 1] +=2.    # larger eyes\n",
    "shape_3d, scale, shift = util.norm_input_face(shape_3d)\n",
    "\n",
    "print(\"Loaded Image...\", file=sys.stderr)\n",
    "\n",
    "au_data = []\n",
    "au_emb = []\n",
    "ains = glob.glob1('examples', '*.wav')\n",
    "ains = [item for item in ains if item is not 'tmp.wav']\n",
    "ains.sort()\n",
    "for ain in ains:\n",
    "    os.system('ffmpeg -y -loglevel error -i examples/{} -ar 16000 examples/tmp.wav'.format(ain))\n",
    "    shutil.copyfile('examples/tmp.wav', 'examples/{}'.format(ain))\n",
    "\n",
    "    # au embedding\n",
    "    from thirdparty.resemblyer_util.speaker_emb import get_spk_emb\n",
    "    me, ae = get_spk_emb('examples/{}'.format(ain))\n",
    "    au_emb.append(me.reshape(-1))\n",
    "\n",
    "    print('Processing audio file', ain)\n",
    "    c = AutoVC_mel_Convertor('examples')\n",
    "\n",
    "    au_data_i = c.convert_single_wav_to_autovc_input(audio_filename=os.path.join('examples', ain),\n",
    "           autovc_model_path=opt_parser.load_AUTOVC_name)\n",
    "    au_data += au_data_i\n",
    "if(os.path.isfile('examples/tmp.wav')):\n",
    "    os.remove('examples/tmp.wav')\n",
    "\n",
    "print(\"Loaded audio...\", file=sys.stderr)\n",
    "\n",
    "# landmark fake placeholder\n",
    "fl_data = []\n",
    "rot_tran, rot_quat, anchor_t_shape = [], [], []\n",
    "for au, info in au_data:\n",
    "    au_length = au.shape[0]\n",
    "    fl = np.zeros(shape=(au_length, 68 * 3))\n",
    "    fl_data.append((fl, info))\n",
    "    rot_tran.append(np.zeros(shape=(au_length, 3, 4)))\n",
    "    rot_quat.append(np.zeros(shape=(au_length, 4)))\n",
    "    anchor_t_shape.append(np.zeros(shape=(au_length, 68 * 3)))\n",
    "\n",
    "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_fl.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_fl.pickle'))\n",
    "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_fl_interp.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_fl_interp.pickle'))\n",
    "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_au.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_au.pickle'))\n",
    "if (os.path.exists(os.path.join('examples', 'dump', 'random_val_gaze.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_gaze.pickle'))\n",
    "\n",
    "with open(os.path.join('examples', 'dump', 'random_val_fl.pickle'), 'wb') as fp:\n",
    "    pickle.dump(fl_data, fp)\n",
    "with open(os.path.join('examples', 'dump', 'random_val_au.pickle'), 'wb') as fp:\n",
    "    pickle.dump(au_data, fp)\n",
    "with open(os.path.join('examples', 'dump', 'random_val_gaze.pickle'), 'wb') as fp:\n",
    "    gaze = {'rot_trans':rot_tran, 'rot_quat':rot_quat, 'anchor_t_shape':anchor_t_shape}\n",
    "    pickle.dump(gaze, fp)\n",
    "\n",
    "model = Audio2landmark_model(opt_parser, jpg_shape=shape_3d)\n",
    "if(len(opt_parser.reuse_train_emb_list) == 0):\n",
    "    model.test(au_emb=au_emb)\n",
    "else:\n",
    "    model.test(au_emb=None)\n",
    "\n",
    "print(\"Audio->Landmark...\", file=sys.stderr)\n",
    "\n",
    "fls = glob.glob1('examples', 'pred_fls_*.txt')\n",
    "fls.sort()\n",
    "\n",
    "for i in range(0,len(fls)):\n",
    "    fl = np.loadtxt(os.path.join('examples', fls[i])).reshape((-1, 68,3))\n",
    "    fl[:, :, 0:2] = -fl[:, :, 0:2]\n",
    "    fl[:, :, 0:2] = fl[:, :, 0:2] / scale - shift\n",
    "\n",
    "    if (ADD_NAIVE_EYE):\n",
    "        fl = util.add_naive_eye(fl)\n",
    "\n",
    "    # additional smooth\n",
    "    fl = fl.reshape((-1, 204))\n",
    "    fl[:, :48 * 3] = savgol_filter(fl[:, :48 * 3], 15, 3, axis=0)\n",
    "    fl[:, 48*3:] = savgol_filter(fl[:, 48*3:], 5, 3, axis=0)\n",
    "    fl = fl.reshape((-1, 68, 3))\n",
    "\n",
    "    ''' STEP 6: Imag2image translation '''\n",
    "    model = Image_translation_block(opt_parser, single_test=True)\n",
    "    with torch.no_grad():\n",
    "        model.single_test(jpg=img, fls=fl, filename=fls[i], prefix=opt_parser.jpg.split('.')[0])\n",
    "        print('finish image2image gen')\n",
    "    os.remove(os.path.join('examples', fls[i]))\n",
    "\n",
    "    print(\"{} / {}: Landmark->Face...\".format(i+1, len(fls)), file=sys.stderr)\n",
    "print(\"Done!\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-sculpture",
   "metadata": {
    "id": "bx83jnNsX7ts"
   },
   "outputs": [],
   "source": [
    "!pip freeze | cat > requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-integer",
   "metadata": {
    "id": "07FWqzIJU5sy"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets==1.4.1\n",
    "!pip install transformers==4.4.2\n",
    "!pip install torchaudio\n",
    "!pip install librosa\n",
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-highland",
   "metadata": {
    "id": "ORtmDPR1bUmj"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "input_values = processor(ds[\"speech\"][0], return_tensors=\"pt\").input_values  # Batch size 1\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "\n",
    "# compute loss\n",
    "target_transcription = \"A MAN SAID TO THE UNIVERSE SIR I EXIST\"\n",
    "\n",
    "# wrap processor as target processor to encode labels\n",
    "with processor.as_target_processor():\n",
    "    labels = processor(transcription, return_tensors=\"pt\").input_ids\n",
    "\n",
    "loss = model(input_values, labels=labels).loss\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-trance",
   "metadata": {
    "id": "iJvMnDnJY5-X"
   },
   "outputs": [],
   "source": [
    "def map_to_array(batch):\n",
    "     speech, _ = sf.read(batch[\"file\"])\n",
    "     batch[\"speech\"] = speech\n",
    "     return batch\n",
    "\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "input_values = processor(ds[\"speech\"][0], return_tensors=\"pt\").input_values  # Batch size 1\n",
    "hidden_states = model(input_values).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-diary",
   "metadata": {
    "id": "zKC7LMMn7k7m"
   },
   "outputs": [],
   "source": [
    "#Chinese\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-operations",
   "metadata": {
    "id": "Vqws5RzBC9CH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-internet",
   "metadata": {
    "id": "TO8kYeIGDcuT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-character",
   "metadata": {
    "id": "YI6OI0m6B-X7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-uncle",
   "metadata": {
    "id": "pz94In6nDwI3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-shaft",
   "metadata": {
    "id": "022dKBB5D5TY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-strike",
   "metadata": {
    "id": "cICFsl8cEEOX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-liberia",
   "metadata": {
    "id": "rJRqQhIAF1SJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-occasions",
   "metadata": {
    "id": "fm1m74gCFBHZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-webster",
   "metadata": {
    "id": "5cyP1VFy9ZMa"
   },
   "outputs": [],
   "source": [
    "AUDIO_HTML = \"\"\"\n",
    "<script>\n",
    "var my_div = document.createElement(\"DIV\");\n",
    "var my_p = document.createElement(\"P\");\n",
    "var my_btn = document.createElement(\"BUTTON\");\n",
    "var t = document.createTextNode(\"Press to start recording\");\n",
    "\n",
    "my_btn.appendChild(t);\n",
    "//my_p.appendChild(my_btn);\n",
    "my_div.appendChild(my_btn);\n",
    "document.body.appendChild(my_div);\n",
    "\n",
    "var base64data = 0;\n",
    "var reader;\n",
    "var recorder, gumStream;\n",
    "var recordButton = my_btn;\n",
    "\n",
    "var handleSuccess = function(stream) {\n",
    "  gumStream = stream;\n",
    "  var options = {\n",
    "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
    "    mimeType : 'audio/webm;codecs=opus'\n",
    "    //mimeType : 'audio/webm;codecs=pcm'\n",
    "  };            \n",
    "  //recorder = new MediaRecorder(stream, options);\n",
    "  recorder = new MediaRecorder(stream);\n",
    "  recorder.ondataavailable = function(e) {            \n",
    "    var url = URL.createObjectURL(e.data);\n",
    "    var preview = document.createElement('audio');\n",
    "    preview.controls = true;\n",
    "    preview.src = url;\n",
    "    document.body.appendChild(preview);\n",
    "\n",
    "    reader = new FileReader();\n",
    "    reader.readAsDataURL(e.data); \n",
    "    reader.onloadend = function() {\n",
    "      base64data = reader.result;\n",
    "      //console.log(\"Inside FileReader:\" + base64data);\n",
    "    }\n",
    "  };\n",
    "  recorder.start();\n",
    "  };\n",
    "\n",
    "recordButton.innerText = \"Recording... press to stop\";\n",
    "\n",
    "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
    "\n",
    "function toggleRecording() {\n",
    "  if (recorder && recorder.state == \"recording\") {\n",
    "      recorder.stop();\n",
    "      gumStream.getAudioTracks()[0].stop();\n",
    "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
    "  }\n",
    "}\n",
    "\n",
    "// https://stackoverflow.com/a/951057\n",
    "function sleep(ms) {\n",
    "  return new Promise(resolve => setTimeout(resolve, ms));\n",
    "}\n",
    "\n",
    "var data = new Promise(resolve=>{\n",
    "//recordButton.addEventListener(\"click\", toggleRecording);\n",
    "recordButton.onclick = ()=>{\n",
    "toggleRecording()\n",
    "\n",
    "sleep(2000).then(() => {\n",
    "  // wait 2000ms for the data to be available...\n",
    "  // ideally this should use something like await...\n",
    "  //console.log(\"Inside data:\" + base64data)\n",
    "  resolve(base64data.toString())\n",
    "\n",
    "});\n",
    "\n",
    "}\n",
    "});\n",
    "      \n",
    "</script>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-purchase",
   "metadata": {
    "id": "XtRvHu4J9iRx"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Audio\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "import wave\n",
    "from scipy.io.wavfile import read as wav_read\n",
    "import io\n",
    "import numpy as np\n",
    "import ffmpeg\n",
    "\n",
    "def write_wav(f, sr, x, normalized=False):\n",
    "    f = wave.open(f, \"wb\")\n",
    "    f.setnchannels(1)\n",
    "    f.setsampwidth(2)\n",
    "    f.setframerate(sr)\n",
    "    \n",
    "    wave_data = x.astype(np.short)\n",
    "    f.writeframes(wave_data.tobytes())\n",
    "    f.close()\n",
    "\n",
    "def get_audio():\n",
    "  global hnum\n",
    "\n",
    "  # call microphone\n",
    "  display(HTML(AUDIO_HTML))\n",
    "  data = eval_js(\"data\")\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "\n",
    "  process = (ffmpeg\n",
    "      .input('pipe:0')\n",
    "      .output('pipe:1', format='wav')\n",
    "      .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
    "  )\n",
    "  output, err = process.communicate(input=binary)\n",
    "\n",
    "  riff_chunk_size = len(output) - 8\n",
    "  # Break up the chunk size into four bytes, held in b.\n",
    "  q = riff_chunk_size\n",
    "  b = []\n",
    "  for i in range(4):\n",
    "      q, r = divmod(q, 256)\n",
    "      b.append(r)\n",
    "\n",
    "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
    "  riff = output[:4] + bytes(b) + output[8:]\n",
    "  sr, audio = wav_read(io.BytesIO(riff))\n",
    "  # save\n",
    "  human_sound_file = \"demo.wav\"\n",
    "  write_wav(human_sound_file, sr, audio)\n",
    "\n",
    "  return human_sound_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-penguin",
   "metadata": {
    "id": "s8VfU0Ta9l2S"
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    Wav2Vec2ForCTC,\n",
    "    Wav2Vec2Processor,\n",
    ")\n",
    "import torch\n",
    "import re\n",
    "import sys\n",
    "\n",
    "model_name = \"voidful/wav2vec2-large-xlsr-53-hk\"\n",
    "device = \"cuda\"\n",
    "processor_name = \"voidful/wav2vec2-large-xlsr-53-hk\"\n",
    "\n",
    "chars_to_ignore_regex = r\"[¥•＂＃＄％＆＇（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､　、〃〈〉《》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏﹑﹔·'℃°•·．﹑︰〈〉─《﹖﹣﹂﹁﹔！？｡。＂＃＄％＆＇（）＊＋，﹐－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏.．!\\\"#$%&()*+,\\-.\\:;<=>?@\\[\\]\\\\\\/^_`{|}~]\"\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name).to(device)\n",
    "processor = Wav2Vec2Processor.from_pretrained(processor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-freedom",
   "metadata": {
    "id": "QVjB-P1o9n_h"
   },
   "outputs": [],
   "source": [
    "resampler = torchaudio.transforms.Resample(orig_freq=48_000, new_freq=16_000)\n",
    "\n",
    "def load_file_to_data(file):\n",
    "    batch = {}\n",
    "    speech, _ = torchaudio.load(file)\n",
    "    batch[\"speech\"] = resampler.forward(speech.squeeze(0)).numpy()\n",
    "    batch[\"sampling_rate\"] = resampler.new_freq\n",
    "    return batch\n",
    "\n",
    "\n",
    "def predict(data):\n",
    "    features = processor(data[\"speech\"], sampling_rate=data[\"sampling_rate\"], padding=True, return_tensors=\"pt\")\n",
    "    input_values = features.input_values.to(device)\n",
    "    attention_mask = features.attention_mask.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values, attention_mask=attention_mask).logits\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    return processor.batch_decode(pred_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-armstrong",
   "metadata": {
    "id": "g_6MxboF9p8J"
   },
   "outputs": [],
   "source": [
    "get_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-rapid",
   "metadata": {
    "id": "5WiSh_md9sL_"
   },
   "outputs": [],
   "source": [
    "predict(load_file_to_data('./demo.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-bottle",
   "metadata": {
    "id": "cldcsU04-EBz"
   },
   "outputs": [],
   "source": [
    "!pip install mecab-python3\n",
    "!pip install unidic-lite\n",
    "!python -m unidic download\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "from datasets import load_dataset\n",
    "import MeCab\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import re\n",
    "\n",
    "# config\n",
    "wakati = MeCab.Tagger(\"-Owakati\")\n",
    "chars_to_ignore_regex = '[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\、\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\。\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\．\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\「\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\」\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\…\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\？\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\・]'\n",
    "\n",
    "# load data, processor and model\n",
    "test_dataset = load_dataset(\"common_voice\", \"ja\", split=\"test[:2%]\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"vumichien/wav2vec2-large-xlsr-japanese\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"vumichien/wav2vec2-large-xlsr-japanese\")\n",
    "resampler = lambda sr, y: librosa.resample(y.numpy().squeeze(), sr, 16_000)\n",
    "\n",
    "# Preprocessing the datasets.\n",
    "def speech_file_to_array_fn(batch):\n",
    "    batch[\"sentence\"] = wakati.parse(batch[\"sentence\"]).strip()\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex,'', batch[\"sentence\"]).strip()\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resampler(sampling_rate, speech_array).squeeze()\n",
    "    return batch\n",
    "test_dataset = test_dataset.map(speech_file_to_array_fn)\n",
    "inputs = processor(test_dataset[\"speech\"][:2], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "print(\"Prediction:\", processor.batch_decode(predicted_ids))\n",
    "print(\"Reference:\", test_dataset[\"sentence\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-belfast",
   "metadata": {
    "id": "ioPI9jML-MsD"
   },
   "outputs": [],
   "source": [
    "!pip install mecab-python3\n",
    "!pip install unidic-lite\n",
    "!python -m unidic download\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "import torchaudio\n",
    "from datasets import load_dataset, load_metric\n",
    "import MeCab\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import re\n",
    "\n",
    "#config\n",
    "wakati = MeCab.Tagger(\"-Owakati\")\n",
    "chars_to_ignore_regex = '[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\、\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\。\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\．\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\「\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\」\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\…\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\？\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\・]'\n",
    "\n",
    "# load data, processor and model\n",
    "test_dataset = load_dataset(\"common_voice\", \"ja\", split=\"test\")\n",
    "wer = load_metric(\"wer\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"vumichien/wav2vec2-large-xlsr-japanese\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"vumichien/wav2vec2-large-xlsr-japanese\")\n",
    "model.to(\"cuda\")\n",
    "resampler = lambda sr, y: librosa.resample(y.numpy().squeeze(), sr, 16_000)\n",
    "\n",
    "# Preprocessing the datasets.\n",
    "def speech_file_to_array_fn(batch):\n",
    "    batch[\"sentence\"] = wakati.parse(batch[\"sentence\"]).strip()\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex,'', batch[\"sentence\"]).strip()\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resampler(sampling_rate, speech_array).squeeze()\n",
    "    return batch\n",
    "test_dataset = test_dataset.map(speech_file_to_array_fn)\n",
    "\n",
    "# evaluate function\n",
    "def evaluate(batch):\n",
    "    inputs = processor(batch[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values.to(\"cuda\"), attention_mask=inputs.attention_mask.to(\"cuda\")).logits\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    batch[\"pred_strings\"] = processor.batch_decode(pred_ids)\n",
    "    return batch\n",
    "result = test_dataset.map(evaluate, batched=True, batch_size=8)\n",
    "print(\"WER: {:2f}\".format(100 * wer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-accessory",
   "metadata": {
    "id": "DC-iTg1F-uuj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-responsibility",
   "metadata": {
    "id": "ULPfLNJP_fXm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "processor = Speech2Textprocessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"patrickvonplaten/librispeech_asr_dummy\",\n",
    "    \"clean\",\n",
    "    split=\"validation\"\n",
    ")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "input_features = processor(\n",
    "    ds[\"speech\"][0],\n",
    "    sampling_rate=16_000,\n",
    "    return_tensors=\"pt\"\n",
    ").input_features  # Batch size 1\n",
    "generated_ids = model.generate(input_ids=input_features)\n",
    "\n",
    "transcription = processor.batch_decode(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "complimentary-algorithm",
   "metadata": {
    "id": "IiEF9KFbK_gZ"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41dadd6d391434a8d72b9a8c684da87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1135.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbdd7d4929a42e6ae0dc9dead3aec24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=118267196.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Speech2Textprocessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5b2286e1ae0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpeech2TextForConditionalGeneration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"facebook/s2t-small-librispeech-asr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprocessor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpeech2Textprocessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"facebook/s2t-small-librispeech-asr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmap_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Speech2Textprocessor' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "processor = Speech2Textprocessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"patrickvonplaten/librispeech_asr_dummy\",\n",
    "    \"clean\",\n",
    "    split=\"validation\"\n",
    ")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "input_features = processor(\n",
    "    ds[\"speech\"][0],\n",
    "    sampling_rate=16_000,\n",
    "    return_tensors=\"pt\"\n",
    ").input_features  # Batch size 1\n",
    "generated_ids = model.generate(input_ids=input_features)\n",
    "\n",
    "transcription = processor.batch_decode(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-jason",
   "metadata": {
    "id": "BIf4Du5pLxQR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Twitch_integration_prototyping.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
